# ----

# ì‘ì„±ëª©ì  : í†µí•© ì˜ìƒ ë¶„ì„ API ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
# ì‘ì„±ì¼ : 2025-06-14

# ë³€ê²½ì‚¬í•­ ë‚´ì—­ (ë‚ ì§œ | ë³€ê²½ëª©ì  | ë³€ê²½ë‚´ìš© | ì‘ì„±ì ìˆœìœ¼ë¡œ ê¸°ì…)
# 2025-06-14 | ìµœì´ˆ êµ¬í˜„ | FastAPI ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ì— ë”°ë¥¸ êµ¬ì¡°ë¡œ ì¬êµ¬ì„± | ì´ì¬ì¸
# 2025-06-16 | êµ¬ì¡° ê°œì„  | DB ì €ì¥, S3 ì—°ë™, LLM ì—°ë™ êµ¬ì¡° ìµœì í™” | ì´ì¬ì¸
# 2025-06-16 | ìë™ ë¶„ì„ | ì„œë²„ ì‹œì‘ ì‹œ S3 ëª¨ë“  ì˜ìƒ ìë™ ë¶„ì„ ê¸°ëŠ¥ ì¶”ê°€ | ì´ì¬ì¸
# 2025-06-17 | ê¸°ëŠ¥ ìµœì í™” | ìë™ ë¶„ì„ ê¸°ëŠ¥ë§Œ ë‚¨ê¸°ê³  ìˆ˜ë™ ì—…ë¡œë“œ ê´€ë ¨ ê¸°ëŠ¥ ì‚­ì œ | ì´ì¬ì¸
# 2025-01-27 | ì‘ë‹µ ìµœì í™” | ë¶„ì„ ì™„ë£Œ í›„ DB ì €ì¥ê¹Œì§€ ì™„ë£Œëœ ìƒíƒœì—ì„œ ì‘ë‹µ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì • | êµ¬ë™ë¹ˆ
# ----

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import asyncio
import os
import tempfile
import json
import shutil
from datetime import datetime
from dotenv import load_dotenv
import sys

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from src.utils.s3_handler import S3Handler
from src.utils.file_utils import FileProcessor
from src.emotion.analyzer import EmotionAnalyzer
from src.eye_tracking.analyzer import EyeTrackingAnalyzer
from src.db.database import get_db_session, setup_database
from src.db.crud import safe_save_analysis_result, safe_get_analysis_results, get_analysis_results_by_user, get_recent_analysis_results, get_analysis_statistics
from src.llm.gpt_analyzer import GPTAnalyzer
from src.db.mariadb_handler import mariadb_handler

# --- Pydantic ëª¨ë¸ ì •ì˜ ---
class AnalysisPayload(BaseModel):
    """ë©”ì¸ ì„œë²„ë¡œë¶€í„° ë¶„ì„ ìš”ì²­ì„ ìˆ˜ì‹ í•  ëª¨ë¸"""
    s3ObjectKey: str

app = FastAPI(
    title="í†µí•© ì˜ìƒ ë¶„ì„ API",
    description="API ìš”ì²­ì„ í†µí•´ S3 ì˜ìƒì„ ë¶„ì„í•˜ì—¬ ê°ì • ë° ì‹œì„  ì¶”ì  ê²°ê³¼ë¥¼ ì œê³µí•˜ëŠ” API",
    version="2.1.0"
)

# ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
_pending_gpt_analyses = []  # GPT ë¶„ì„ ëŒ€ê¸° í
_batch_processing_active = False  # ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™” ìƒíƒœ

@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    print("ğŸš€ ë¶„ì„ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # MongoDB ì—°ê²° ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
    try:
        setup_database()
        print("âœ… MongoDB ì—°ê²°ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âš ï¸ MongoDB ì—°ê²° ì‹¤íŒ¨ - ì• í”Œë¦¬ì¼€ì´ì…˜ì€ MongoDB ì—†ì´ ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤: {e}")
    
    # MariaDB ì—°ê²° ì‹œë„
    try:
        await mariadb_handler.create_pool()
        print("âœ… MariaDB ì—°ê²°ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âš ï¸ MariaDB ì—°ê²° ì‹¤íŒ¨: {e}")
        print("ğŸ“ MariaDB ì—†ì´ ê³„ì† ì‹¤í–‰ë©ë‹ˆë‹¤.")
    
    print("ğŸš€ ë¶„ì„ ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. API ìš”ì²­ì„ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
    
    # âš ï¸ S3 ìë™ ë¶„ì„ ë¡œì§ ì œê±°
    # print("ğŸ“¡ S3 ìë™ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    # asyncio.create_task(auto_analyze_all_s3_videos())

@app.on_event("shutdown")
async def shutdown_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸"""
    try:
        await mariadb_handler.close_pool()
        print("âœ… ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âš ï¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ìš”ì²­ ëª¨ë¸ (ìë™ ë¶„ì„ ê´€ë ¨ë§Œ)
class S3UserVideoRequest(BaseModel):
    """S3 ì‚¬ìš©ìë³„ ì˜ìƒ ë¶„ì„ ìš”ì²­"""
    user_id: str  # ì‚¬ìš©ì ID (ì˜ˆ: "iv001", "user123")
    question_num: str  # ì§ˆë¬¸ ë²ˆí˜¸ (ì˜ˆ: "Q001", "1", "question_1")
    session_id: Optional[str] = None

class AnalysisResponse(BaseModel):
    analysis_id: str
    status: str
    message: str
    results: Optional[Dict[str, Any]] = None

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
s3_handler = S3Handler()
file_processor = FileProcessor()
emotion_analyzer = EmotionAnalyzer()
eye_tracking_analyzer = EyeTrackingAnalyzer()
gpt_analyzer = GPTAnalyzer()

# --- ì˜ìƒ ìˆ˜ì‹  API ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/analysis/attitude", response_model=AnalysisResponse)
async def analyze_video_from_s3_key(payload: AnalysisPayload):
    """
    ë©”ì¸ ì„œë²„ë¡œë¶€í„° S3 Object Keyë¥¼ ë°›ì•„ ì˜ìƒ ë¶„ì„ì„ ì™„ë£Œí•œ í›„ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    í´ë§ ë°©ì‹ìœ¼ë¡œ ë¶„ì„ ì‘ì—…ì„ ì²˜ë¦¬í•˜ê³  ì™„ë£Œ í›„ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        s3_key = payload.s3ObjectKey
        print(f"ğŸ“¥ ë¶„ì„ ìš”ì²­ ìˆ˜ì‹ : {s3_key}")
        
        # S3 í‚¤ë¡œë¶€í„° ì‚¬ìš©ì IDì™€ ì§ˆë¬¸ ë²ˆí˜¸ ì¶”ì¶œ
        try:
            # ì˜ˆ: 'team12/interview_video/7/1/1ë²ˆ.webm' -> user_id='7', question_num='1'
            parts = s3_key.split('/')
            print(f"ğŸ” S3 í‚¤ íŒŒì‹±: {s3_key} -> parts: {parts}")
            
            if len(parts) < 4:
                raise IndexError("S3 key does not contain enough parts for team/folder/user_id/question_num structure.")
            
            # team12/interview_video/7/1/1ë²ˆ.webm êµ¬ì¡°ì—ì„œ ì¶”ì¶œ
            user_id = parts[2]  # ì„¸ ë²ˆì§¸ ë¶€ë¶„ì´ ì§€ì›ì ë²ˆí˜¸
            question_num = parts[3]  # ë„¤ ë²ˆì§¸ ë¶€ë¶„ì´ ì§ˆë¬¸ ë²ˆí˜¸
            
            print(f"âœ… íŒŒì‹± ê²°ê³¼: user_id='{user_id}', question_num='{question_num}'")
            
        except IndexError:
            raise HTTPException(
                status_code=400,
                detail=f"ì˜ëª»ëœ S3 í‚¤ í˜•ì‹ì…ë‹ˆë‹¤. 'team/interview_video/user_id/question_num/...' í˜•ì‹ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤: {s3_key}"
            )
            
        analysis_id = f"api_s3_analysis_{user_id}_{question_num}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        bucket_name = os.getenv('S3_BUCKET_NAME', 'skala25a')
        session_id = f"api_triggered_{user_id}"

        print(f"ğŸ¬ ë¶„ì„ ì‹œì‘ (í´ë§ ë°©ì‹): {user_id}/{question_num} -> {s3_key}")
        
        # 1. ë¶„ì„ ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹œì‘
        asyncio.create_task(process_s3_user_video_analysis(
            analysis_id,
            bucket_name,
            s3_key,
            user_id,
            question_num,
            session_id,
            return_result=False
        ))
        
        print(f"ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì‹œì‘ë¨: {analysis_id}")
        
        # 2. í´ë§ì„ í†µí•´ ë¶„ì„ ì™„ë£Œ ëŒ€ê¸°
        max_polling_time = 900  # 15ë¶„
        polling_interval = 5    # 5ì´ˆ
        polling_count = 0
        max_polls = max_polling_time // polling_interval
        
        while polling_count < max_polls:
            await asyncio.sleep(polling_interval)
            polling_count += 1
            
            # MongoDBì—ì„œ ë¶„ì„ ê²°ê³¼ í™•ì¸
            try:
                result = safe_get_analysis_results(analysis_id)
                
                if result:
                    status = result.get("status", "processing")
                    print(f"ğŸ“Š ë¶„ì„ ìƒíƒœ í™•ì¸ ({polling_count}/{max_polls}): {status}")
                    
                    if status == "completed":
                        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {analysis_id}")
                        return AnalysisResponse(
                            analysis_id=analysis_id,
                            status="completed",
                            message=f"ì‚¬ìš©ì {user_id}, ì§ˆë¬¸ {question_num} ì˜ìƒ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                            results=result
                        )
                    elif status == "error":
                        error_msg = result.get("error", "Unknown error")
                        print(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {analysis_id} - {error_msg}")
                        return AnalysisResponse(
                            analysis_id=analysis_id,
                            status="error",
                            message=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}",
                            results=None
                        )
                else:
                    print(f"â³ ë¶„ì„ ëŒ€ê¸° ì¤‘ ({polling_count}/{max_polls}): {analysis_id}")
                    
            except Exception as polling_error:
                print(f"âš ï¸ í´ë§ ì¤‘ ì˜¤ë¥˜ (ì‹œë„ {polling_count}): {str(polling_error)}")
                continue
        
        # 3. íƒ€ì„ì•„ì›ƒ ë°œìƒ
        print(f"â° ë¶„ì„ íƒ€ì„ì•„ì›ƒ: {analysis_id}")
        raise HTTPException(
            status_code=504,
            detail=f"ë¶„ì„ ì‹œê°„ ì´ˆê³¼ (15ë¶„). ë¶„ì„ ID: {analysis_id}"
        )

    except HTTPException as http_exc:
        raise http_exc
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ì— ëŒ€í•œ ë¡œê¹… ê°•í™”
        print(f"ğŸ”¥ /analysis/attitude ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {"message": "í†µí•© ì˜ìƒ ë¶„ì„ API (ìë™ ë¶„ì„ ì „ìš©)ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."}

@app.get("/s3/available-users-questions")
async def get_available_users_and_questions():
    """
    S3ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚¬ìš©ìì™€ ì§ˆë¬¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        bucket_name = os.getenv('S3_BUCKET_NAME', 'skala25a')
        available_videos = await s3_handler.list_available_users_and_questions(bucket_name)
        
        return {
            "bucket": bucket_name,
            "available_videos": available_videos,
            "total_users": len(available_videos),
            "total_videos": sum(len(questions) for questions in available_videos.values())
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"S3 ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/s3/find-video/{user_id}/{question_num}")
async def find_specific_video(user_id: str, question_num: str):
    """
    íŠ¹ì • ì‚¬ìš©ì/ì§ˆë¬¸ì˜ ì˜ìƒ íŒŒì¼ì„ S3ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    try:
        bucket_name = os.getenv('S3_BUCKET_NAME', 'skala25a')
        video_key = await s3_handler.find_video_file(bucket_name, user_id, question_num)
        
        if video_key:
            return {
                "found": True,
                "user_id": user_id,
                "question_num": question_num,
                "s3_key": video_key,
                "s3_url": f"s3://{bucket_name}/{video_key}"
            }
        else:
            return {
                "found": False,
                "user_id": user_id,
                "question_num": question_num,
                "message": "í•´ë‹¹ ì‚¬ìš©ì/ì§ˆë¬¸ì˜ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì˜ìƒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")

@app.post("/analyze-s3-user-video", response_model=AnalysisResponse)
async def analyze_s3_user_video(request: S3UserVideoRequest, background_tasks: BackgroundTasks):
    """
    S3ì—ì„œ íŠ¹ì • ì‚¬ìš©ì/ì§ˆë¬¸ì˜ ì˜ìƒì„ ë¶„ì„í•©ë‹ˆë‹¤. (ìˆ˜ë™ íŠ¸ë¦¬ê±°)
    """
    try:
        # ë¶„ì„ ID ìƒì„±
        analysis_id = f"manual_s3_analysis_{request.user_id}_{request.question_num}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # S3 ì„¤ì •
        bucket_name = os.getenv('S3_BUCKET_NAME', 'skala25a')
        
        # ì˜ìƒ íŒŒì¼ ê²€ìƒ‰
        video_key = await s3_handler.find_video_file(bucket_name, request.user_id, request.question_num)
        
        if not video_key:
            raise HTTPException(
                status_code=404, 
                detail=f"ì‚¬ìš©ì {request.user_id}, ì§ˆë¬¸ {request.question_num}ì˜ ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        print(f"ğŸ¬ ìˆ˜ë™ ë¶„ì„ ì‹œì‘: {request.user_id}/{request.question_num} -> {video_key}")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹¤í–‰
        background_tasks.add_task(
            process_s3_user_video_analysis,
            analysis_id,
            bucket_name,
            video_key,
            request.user_id,
            request.question_num,
            request.session_id or "manual",
            return_result=False
        )
        
        return AnalysisResponse(
            analysis_id=analysis_id,
            status="processing",
            message=f"ì‚¬ìš©ì {request.user_id}, ì§ˆë¬¸ {request.question_num} ì˜ìƒ ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")

@app.get("/analysis/{analysis_id}")
async def get_analysis_result(analysis_id: str):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        result = safe_get_analysis_results(analysis_id)
        
        if result:
            return result
        else:
            raise HTTPException(status_code=404, detail="ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/analysis/{analysis_id}/llm-comment")
async def get_llm_comment(analysis_id: str):
    """
    íŠ¹ì • ë¶„ì„ì˜ LLM ì½”ë©˜íŠ¸ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        with get_db_session() as db:
            if db is None:
                return {"message": "MongoDB ì—°ê²° ì—†ìŒ - LLM ì½”ë©˜íŠ¸ ì¡°íšŒ ë¶ˆê°€"}
            
            collection = db['llm_comments']
            comment = collection.find_one({"analysis_id": analysis_id})
            
            if not comment:
                return {"message": "LLM ì½”ë©˜íŠ¸ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
            
            # ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            if '_id' in comment:
                comment['_id'] = str(comment['_id'])
            
            return comment
            
    except Exception as e:
        return {"message": f"LLM ì½”ë©˜íŠ¸ ì¡°íšŒ ì‹¤íŒ¨ (ìŠ¤í‚µë¨): {str(e)}"}

@app.get("/analysis/recent")
async def get_recent_analyses(limit: int = 10):
    """
    ìµœê·¼ ë¶„ì„ ê²°ê³¼ë“¤ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        results = get_recent_analysis_results(limit)
        return {"recent_analyses": results, "count": len(results)}
        
    except Exception as e:
        return {"recent_analyses": [], "count": 0, "message": f"ìµœê·¼ ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨ (ìŠ¤í‚µë¨): {str(e)}"}

@app.get("/analysis/{analysis_id}/status")
async def get_analysis_status(analysis_id: str):
    """
    ë¶„ì„ ì§„í–‰ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        result = safe_get_analysis_results(analysis_id)
        
        if result:
            # í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ
            status_info = {
                "analysis_id": result.get("analysis_id"),
                "status": result.get("status"),
                "progress": result.get("progress", 0),
                "stage": result.get("stage"),
                "created_at": result.get("created_at"),
                "completed_at": result.get("completed_at")
            }
            return status_info
        else:
            raise HTTPException(status_code=404, detail="ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/analysis/{analysis_id}/cancel")
async def cancel_analysis(analysis_id: str):
    """
    ì§„í–‰ ì¤‘ì¸ ë¶„ì„ì„ ì·¨ì†Œí•©ë‹ˆë‹¤. (ì‹¤ì œë¡œëŠ” ìƒíƒœë§Œ ë³€ê²½)
    """
    try:
        with get_db_session() as db:
            if db is None:
                return {"message": "MongoDB ì—°ê²° ì—†ìŒ - ë¶„ì„ ì·¨ì†Œ ë¶ˆê°€", "analysis_id": analysis_id}
            
            collection = db['analysis_results']
            result = collection.update_one(
                {"analysis_id": analysis_id, "status": "processing"},
                {"$set": {"status": "cancelled", "cancelled_at": datetime.now().isoformat()}}
            )
            
            if result.matched_count == 0:
                raise HTTPException(status_code=404, detail="ì·¨ì†Œí•  ìˆ˜ ìˆëŠ” ë¶„ì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            return {"message": "ë¶„ì„ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.", "analysis_id": analysis_id}
            
    except HTTPException:
        raise
    except Exception as e:
        return {"message": f"ë¶„ì„ ì·¨ì†Œ ì‹¤íŒ¨ (ìŠ¤í‚µë¨): {str(e)}", "analysis_id": analysis_id}

@app.get("/interview-attitude/{user_id}")
async def get_interview_attitude_by_user(user_id: str):
    """
    íŠ¹ì • ì‚¬ìš©ìì˜ ëª¨ë“  ë©´ì ‘íƒœë„ í‰ê°€ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        scores = await mariadb_handler.get_interview_attitude(user_id)
        
        if not scores:
            return {"message": f"ì‚¬ìš©ì {user_id}ì˜ ë©´ì ‘íƒœë„ í‰ê°€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "scores": []}
        
        return {
            "user_id": user_id,
            "scores": scores,
            "count": len(scores) if isinstance(scores, list) else 1
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©´ì ‘íƒœë„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/interview-attitude/{user_id}/{question_num}")
async def get_interview_attitude_by_user_question(user_id: str, question_num: str):
    """
    íŠ¹ì • ì‚¬ìš©ì/ì§ˆë¬¸ì˜ ë©´ì ‘íƒœë„ í‰ê°€ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        score = await mariadb_handler.get_interview_attitude(user_id, question_num)
        
        if not score:
            raise HTTPException(
                status_code=404, 
                detail=f"ì‚¬ìš©ì {user_id}, ì§ˆë¬¸ {question_num}ì˜ ë©´ì ‘íƒœë„ í‰ê°€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        return score
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë©´ì ‘íƒœë„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@app.get("/health")
async def health_check():
    """
    ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        # MongoDB ì—°ê²° í™•ì¸
        mongodb_status = "healthy"
        try:
            with get_db_session() as db:
                if db is not None:
                    db.list_collection_names()
                else:
                    mongodb_status = "disconnected"
        except Exception as e:
            mongodb_status = f"error: {str(e)}"
        
        # MariaDB ì—°ê²° í™•ì¸
        mariadb_status = "healthy"
        try:
            await mariadb_handler.test_connection()
        except Exception as e:
            mariadb_status = f"error: {str(e)}"
        
        # S3 ì—°ê²° í™•ì¸
        s3_status = "healthy"
        try:
            bucket_name = os.getenv('S3_BUCKET_NAME', 'skala25a')
            await s3_handler.test_connection(bucket_name)
        except Exception as e:
            s3_status = f"error: {str(e)}"
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "services": {
                "mongodb": mongodb_status,
                "mariadb": mariadb_status,
                "s3": s3_status
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

@app.post("/test/yaml-keywords")
async def test_yaml_keywords(analysis_data: Dict[str, Any] = None):
    """YAML ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        from src.llm.keyword_analyzer import keyword_analyzer
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (ìš”ì²­ì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        if not analysis_data:
            analysis_data = {
                'emotion_score': 45,
                'eye_score': 28,
                'concentration_score': 15,
                'stability_score': 8,
                'blink_score': 5,
                'total_violations': 3,
                'face_multiple_detected': False,
                'suspected_copying': False,
                'suspected_impersonation': False,
                'dominant_emotions': 'neutral',
                'emotion_stability': 'ë³´í†µ'
            }
        
        # í‚¤ì›Œë“œ ë¶„ì„ ì‹¤í–‰
        result = keyword_analyzer.analyze_keywords(analysis_data)
        
        # GPT í”„ë¡¬í”„íŠ¸ë„ ìƒì„±í•´ë³´ê¸°
        system_prompt, user_prompt = keyword_analyzer.get_gpt_prompt(analysis_data)
        
        return {
            "status": "success",
            "keyword_analysis": result,
            "gpt_prompts": {
                "system_prompt": system_prompt[:500] + "..." if len(system_prompt) > 500 else system_prompt,
                "user_prompt": user_prompt[:500] + "..." if len(user_prompt) > 500 else user_prompt
            },
            "input_data": analysis_data
        }
        
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "input_data": analysis_data or {}
        }

@app.post("/test/mariadb-save")
async def test_mariadb_save(request: dict):
    """MariaDB ì €ì¥ í…ŒìŠ¤íŠ¸ (ìƒˆë¡œìš´ ID í˜•ì‹)"""
    try:
        user_id = request.get("user_id", "123")
        question_num = request.get("question_num", "1")
        emotion_score = request.get("emotion_score", 45.0)
        eye_score = request.get("eye_score", 28.0)
        suspected_copying = request.get("suspected_copying", False)
        suspected_impersonation = request.get("suspected_impersonation", False)
        gpt_analysis = request.get("gpt_analysis", {})
        
        # MariaDBì— ì €ì¥
        success = await mariadb_handler.save_interview_attitude(
            user_id=user_id,
            question_num=question_num,
            emotion_score=emotion_score,
            eye_score=eye_score,
            suspected_copying=suspected_copying,
            suspected_impersonation=suspected_impersonation,
            gpt_analysis=gpt_analysis
        )
        
        if success:
            # ì €ì¥ëœ ë°ì´í„° ì¡°íšŒ
            saved_data = await mariadb_handler.get_interview_attitude(user_id, question_num)
            
            return {
                "status": "success",
                "message": f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ (ìƒˆë¡œìš´ ID í˜•ì‹)",
                "request_data": request,
                "id_format": {
                    "ANS_SCORE_ID": f"{user_id}0{question_num}",
                    "INTV_ANS_ID": f"{user_id}0{question_num}", 
                    "ANS_CAT_RESULT_ID": f"{user_id}0{question_num}0"
                },
                "saved_data": saved_data
            }
        else:
            return {"status": "error", "message": "ë°ì´í„° ì €ì¥ ì‹¤íŒ¨"}
            
    except Exception as e:
        logger.error(f"MariaDB í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/test/yaml-all-features")
async def test_yaml_all_features():
    """ëª¨ë“  YAML ê¸°ë°˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    try:
        from src.llm.keyword_analyzer import keyword_analyzer
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_emotion_result = {
            'interview_score': 45,
            'dominant_emotion': 'neutral',
            'emotion_ratios': {'happy': 0.3, 'neutral': 0.6, 'sad': 0.1},
            'detailed_analysis': {
                'scores': {'expressiveness': 30, 'stability': 25},
                'improvement_suggestions': ['í‘œì • ë‹¤ì–‘ì„± ê°œì„ ']
            },
            'total_frames': 1500,
            'emotion_counts': {'happy': 450, 'neutral': 900, 'sad': 150},
            'confidence_scores': {'happy': 0.85, 'neutral': 0.75, 'sad': 0.6},
            'grade': 'B'
        }
        
        test_eye_result = {
            'basic_scores': {
                'total_eye_score': 28,
                'concentration_score': 15,
                'stability_score': 8,
                'blink_score': 5
            },
            'analysis_summary': {
                'total_violations': 3,
                'face_multiple_detected': False,
                'center_time_ratio': 0.7
            },
            'total_duration': 60.0,
            'blink_count': 45,
            'blink_rate': 0.75,
            'attention_score': 25,
            'gaze_stability': 20,
            'focus_score': 22
        }
        
        analysis_data = {
            'emotion_score': 45,
            'eye_score': 28,
            'concentration_score': 15,
            'stability_score': 8,
            'blink_score': 5,
            'total_violations': 3,
            'face_multiple_detected': False,
            'suspected_copying': False,
            'suspected_impersonation': False,
            'dominant_emotions': 'neutral',
            'emotion_stability': 'ë³´í†µ'
        }
        
        # 1. í‚¤ì›Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸
        keywords = keyword_analyzer.analyze_keywords(analysis_data)
        
        # 2. GPT í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        gpt_prompt = keyword_analyzer.get_gpt_prompt(analysis_data)
        
        # 3. ìƒì„¸ GPT í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸
        detailed_prompt = keyword_analyzer.get_detailed_gpt_prompt(test_emotion_result, test_eye_result)
        
        # 4. ë™ì  í”¼ë“œë°± ìƒì„± í…ŒìŠ¤íŠ¸
        dynamic_feedback = keyword_analyzer.generate_dynamic_feedback(test_emotion_result, test_eye_result)
        
        return {
            "status": "success",
            "message": "âœ… ëª¨ë“  YAML ê¸°ë°˜ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤",
            "test_results": {
                "1_keyword_analysis": keywords,
                "2_gpt_prompt": {
                    "system": gpt_prompt[0][:300] + "..." if len(gpt_prompt[0]) > 300 else gpt_prompt[0],
                    "user": gpt_prompt[1][:300] + "..." if len(gpt_prompt[1]) > 300 else gpt_prompt[1]
                },
                "3_detailed_prompt": {
                    "system": detailed_prompt[0][:300] + "..." if len(detailed_prompt[0]) > 300 else detailed_prompt[0],
                    "user": detailed_prompt[1][:300] + "..." if len(detailed_prompt[1]) > 300 else detailed_prompt[1]
                },
                "4_dynamic_feedback": dynamic_feedback
            },
            "test_data": {
                "emotion_result": test_emotion_result,
                "eye_result": test_eye_result,
                "analysis_data": analysis_data
            }
        }
        
    except Exception as e:
        logger.error(f"YAML ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/auto-analysis/status")
async def get_auto_analysis_status():
    """
    ìë™ ë¶„ì„ ì§„í–‰ ìƒí™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        # MongoDB í†µê³„ ì¡°íšŒ (ì—°ê²° ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜)
        statistics = get_analysis_statistics()
        recent_analyses = get_recent_analysis_results(10)
        
        # ìµœê·¼ ë¶„ì„ ê²°ê³¼ í˜•íƒœ ë³€í™˜
        formatted_recent = []
        for doc in recent_analyses:
            formatted_recent.append({
                "analysis_id": doc.get("analysis_id"),
                "user_id": doc.get("user_id"),
                "question_num": doc.get("question_num"),
                "status": doc.get("status"),
                "created_at": doc.get("created_at"),
                "session_id": doc.get("session_id")
            })
        
        # ê¸°ë³¸ ì‘ë‹µ
        response = {
            "timestamp": datetime.now().isoformat(),
            "total_statistics": {
                "total_analyses": statistics.get("total_analyses", 0),
                "completed": statistics.get("status_breakdown", {}).get("completed", 0),
                "processing": statistics.get("status_breakdown", {}).get("processing", 0),
                "failed": statistics.get("status_breakdown", {}).get("error", 0),
                "completion_rate": 0
            },
            "recent_analyses": formatted_recent
        }
        
        # ì™„ë£Œìœ¨ ê³„ì‚°
        total = response["total_statistics"]["total_analyses"]
        completed = response["total_statistics"]["completed"]
        if total > 0:
            response["total_statistics"]["completion_rate"] = round(completed / total * 100, 1)
        
        # MongoDB ì—°ê²° ìƒíƒœ ì •ë³´ ì¶”ê°€
        if "note" in statistics:
            response["note"] = statistics["note"]
        
        return response
        
    except Exception as e:
        return {
            "timestamp": datetime.now().isoformat(),
            "error": f"ìë™ ë¶„ì„ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
            "total_statistics": {
                "total_analyses": 0,
                "completed": 0,
                "processing": 0,
                "failed": 0,
                "completion_rate": 0
            },
            "recent_analyses": []
        }

@app.post("/auto-analysis/restart")
async def restart_auto_analysis():
    """
    ìë™ ë¶„ì„ì„ ìˆ˜ë™ìœ¼ë¡œ ì¬ì‹œì‘í•©ë‹ˆë‹¤.
    """
    try:
        print("ğŸ”„ ìë™ ë¶„ì„ì„ ìˆ˜ë™ìœ¼ë¡œ ì¬ì‹œì‘í•©ë‹ˆë‹¤...")
        asyncio.create_task(auto_analyze_all_s3_videos())
        
        return {
            "message": "ìë™ ë¶„ì„ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìë™ ë¶„ì„ ì¬ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/gpt-batch/status")
async def get_gpt_batch_status():
    """GPT ë°°ì¹˜ ì²˜ë¦¬ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    global _pending_gpt_analyses, _batch_processing_active
    
    return {
        "batch_processing_active": _batch_processing_active,
        "pending_analyses": len(_pending_gpt_analyses),
        "queue": [
            {
                "analysis_id": item["analysis_id"],
                "user_id": item["user_id"], 
                "question_num": item["question_num"],
                "added_at": item["added_at"].isoformat()
            }
            for item in _pending_gpt_analyses
        ]
    }

@app.post("/gpt-batch/trigger")
async def trigger_gpt_batch(background_tasks: BackgroundTasks):
    """ìˆ˜ë™ìœ¼ë¡œ GPT ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
    global _pending_gpt_analyses
    
    if not _pending_gpt_analyses:
        return {
            "status": "success",
            "message": "GPT ë¶„ì„ ëŒ€ê¸° í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.",
            "pending_count": 0
        }
    
    try:
        pending_count = len(_pending_gpt_analyses)
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ GPT ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘
        background_tasks.add_task(process_gpt_batch)
        
        return {
            "status": "success", 
            "message": f"GPT ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.",
            "pending_count": pending_count,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPT ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")

@app.post("/gpt-batch/check-and-trigger")
async def check_and_trigger_gpt_batch_endpoint(background_tasks: BackgroundTasks):
    """ì˜ìƒ ë¶„ì„ ì™„ë£Œ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  í•„ìš”ì‹œ GPT ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í™•ì¸ ë° íŠ¸ë¦¬ê±°
        background_tasks.add_task(check_and_trigger_gpt_batch)
        
        return {
            "status": "success",
            "message": "GPT ë°°ì¹˜ ì²˜ë¦¬ í™•ì¸ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"GPT ë°°ì¹˜ í™•ì¸ ì‹¤íŒ¨: {str(e)}")

# === ë‚´ë¶€ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ===

async def process_s3_user_video_analysis(
    analysis_id: str,
    s3_bucket: str,
    s3_key: str,
    user_id: str,
    question_num: str,
    session_id: Optional[str],
    return_result: bool = False
):
    """
    S3 ì‚¬ìš©ìë³„ ì˜ìƒ ë¶„ì„ ì›Œí¬í”Œë¡œìš°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        return_result: Trueë©´ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ê³  ìƒì„¸ ë¡œê·¸ ì¶œë ¥ (ë™ê¸° ëª¨ë“œ)
                      Falseë©´ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ëª¨ë“œ (ê¸°ë³¸ê°’)
    """
    temp_dir = None
    start_time = datetime.now()
    processing_times = {}
    
    try:
        if return_result:
            print(f"ğŸ“Š ë¶„ì„ ì‹œì‘: {analysis_id}")
        else:
            # ë¶„ì„ ìƒíƒœë¥¼ PROCESSINGìœ¼ë¡œ ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œë§Œ)
            await update_analysis_status(analysis_id, "processing", "download", 10.0)
        
        # 1. ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„± ë° S3 ë‹¤ìš´ë¡œë“œ
        stage_start = datetime.now()
        if return_result:
            print(f"ğŸ“¥ S3ì—ì„œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘... ({s3_key})")
        temp_dir = tempfile.mkdtemp(prefix="video_analysis_")
        video_path = await s3_handler.download_file(s3_bucket, s3_key, temp_dir)
        processing_times["download"] = (datetime.now() - stage_start).total_seconds()
        if return_result:
            print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({processing_times['download']:.2f}ì´ˆ)")
        
        if not return_result:
            await update_analysis_status(analysis_id, "processing", "emotion_analysis", 30.0)
        
        # 2. ì˜ìƒ/ìŒì„± ë¶„ë¦¬ (í•„ìš”ì‹œ)
        if return_result:
            print(f"ğŸ¬ ì˜ìƒ ì „ì²˜ë¦¬ ì¤‘...")
        processed_video_path = await file_processor.process_video(video_path)
        
        # 3. ê°ì • ë¶„ì„ ì‹¤í–‰
        stage_start = datetime.now()
        if return_result:
            print(f"ğŸ˜Š ê°ì • ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        emotion_result = await emotion_analyzer.analyze_video(processed_video_path)
        processing_times["emotion_analysis"] = (datetime.now() - stage_start).total_seconds()
        if return_result:
            print(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ ({processing_times['emotion_analysis']:.2f}ì´ˆ) - ì ìˆ˜: {emotion_result.get('interview_score', 0)}")
        
        if not return_result:
            await update_analysis_status(analysis_id, "processing", "eye_tracking", 60.0)
        
        # 4. ì‹œì„  ì¶”ì  ë¶„ì„ ì‹¤í–‰
        stage_start = datetime.now()
        if return_result:
            print(f"ğŸ‘ï¸ ì‹œì„  ì¶”ì  ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        eye_tracking_result = await eye_tracking_analyzer.analyze_video(processed_video_path)
        processing_times["eye_tracking"] = (datetime.now() - stage_start).total_seconds()
        if return_result:
            print(f"âœ… ì‹œì„  ì¶”ì  ë¶„ì„ ì™„ë£Œ ({processing_times['eye_tracking']:.2f}ì´ˆ) - ì ìˆ˜: {eye_tracking_result.get('basic_scores', {}).get('total_eye_score', 0)}")
        
        if not return_result:
            await update_analysis_status(analysis_id, "processing", "llm_analysis", 80.0)
        
        # 5. LLMìœ¼ë¡œ ì¢…í•© ë¶„ì„ ë° ì½”ë©˜íŠ¸ ìƒì„±
        stage_start = datetime.now()
        if return_result:
            print(f"ğŸ¤– LLM ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            llm_comment = await gpt_analyzer.analyze_interview_results(
                emotion_result, eye_tracking_result, user_id, question_num
            )
        else:
            llm_comment = await gpt_analyzer.generate_comment(
                emotion_result, eye_tracking_result, analysis_id
            )
        processing_times["llm_analysis"] = (datetime.now() - stage_start).total_seconds()
        if return_result:
            print(f"âœ… LLM ë¶„ì„ ì™„ë£Œ ({processing_times['llm_analysis']:.2f}ì´ˆ)")
        
        if not return_result:
            await update_analysis_status(analysis_id, "processing", "save_results", 95.0)
        
        # 6. ê²°ê³¼ë¥¼ MongoDBì— ì €ì¥
        stage_start = datetime.now()
        if return_result:
            print(f"ğŸ’¾ MongoDBì— ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘...")
        total_processing_time = (datetime.now() - start_time).total_seconds()
        
        analysis_data = {
            "analysis_id": analysis_id,
            "user_id": user_id,
            "session_id": session_id,
            "s3_bucket": s3_bucket,
            "s3_key": s3_key,
            "emotion_analysis": emotion_result,
            "eye_tracking_analysis": eye_tracking_result,
            "llm_comment_id": str(llm_comment.id) if hasattr(llm_comment, 'id') else None,
            "processing_times": processing_times,
            "total_processing_time": total_processing_time,
            "created_at": start_time.isoformat(),
            "completed_at": datetime.now().isoformat(),
            "status": "completed"
        }
        
        # MongoDBì— ë¶„ì„ ê²°ê³¼ ì €ì¥ (ì—°ê²° ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ)
        save_success = safe_save_analysis_result(analysis_data)
        if save_success:
            if return_result:
                print(f"âœ… MongoDBì— ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
            else:
                print(f"âœ… MongoDBì— ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {analysis_id}")
        else:
            if return_result:
                print(f"âš ï¸ MongoDB ì €ì¥ ì‹¤íŒ¨ - ìŠ¤í‚µë¨")
            else:
                print(f"âš ï¸ MongoDB ì €ì¥ ì‹¤íŒ¨ - ìŠ¤í‚µë¨: {analysis_id}")
        
        # 7. MariaDBì— ë©´ì ‘íƒœë„ í‰ê°€ ì €ì¥
        if return_result:
            print(f"ğŸ’¾ MariaDBì— ë©´ì ‘íƒœë„ í‰ê°€ ì €ì¥ ì¤‘...")
        try:
            # ì ìˆ˜ ì¶”ì¶œ
            emotion_score_60 = emotion_result.get('interview_score', 0)  # 60ì  ë§Œì 
            eye_score_40 = eye_tracking_result.get('basic_scores', {}).get('total_eye_score', 0)  # 40ì  ë§Œì 
            
            # ë¶€ì •í–‰ìœ„ ê°ì§€ ê²°ê³¼ ì¶”ì¶œ
            suspected_copying = eye_tracking_result.get('analysis_summary', {}).get('total_violations', 0) >= 5
            suspected_impersonation = eye_tracking_result.get('analysis_summary', {}).get('face_multiple_detected', False)
            
            # GPT ë¶„ì„ ê²°ê³¼ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            strength_keywords = llm_comment.strengths if llm_comment.strengths else ['ì„±ì‹¤í•œ íƒœë„']
            weakness_keywords = llm_comment.weaknesses if llm_comment.weaknesses else ['ê°œì„  í•„ìš”']
            
            gpt_analysis = {
                'strength_keyword': '\n'.join(strength_keywords),
                'weakness_keyword': '\n'.join(weakness_keywords)
            }
            
            mariadb_success = await mariadb_handler.save_interview_attitude(
                user_id=user_id,
                question_num=question_num,
                emotion_score=emotion_score_60,
                eye_score=eye_score_40,
                suspected_copying=suspected_copying,
                suspected_impersonation=suspected_impersonation,
                gpt_analysis=gpt_analysis
            )
            
            if mariadb_success:
                if return_result:
                    print(f"âœ… MariaDBì— ë©´ì ‘íƒœë„ í‰ê°€ ì €ì¥ ì™„ë£Œ (ê°ì •:{emotion_score_60:.1f}, ì‹œì„ :{eye_score_40:.1f})")
                else:
                    print(f"âœ… MariaDBì— ë©´ì ‘íƒœë„ í‰ê°€ ì €ì¥ ì™„ë£Œ: {user_id}/{question_num} (ê°ì •:{emotion_score_60:.1f}, ì‹œì„ :{eye_score_40:.1f})")
            else:
                if return_result:
                    print(f"âš ï¸ MariaDB ì €ì¥ ì‹¤íŒ¨")
                else:
                    print(f"âš ï¸ MariaDB ì €ì¥ ì‹¤íŒ¨: {user_id}/{question_num}")
                    
        except Exception as mariadb_error:
            if return_result:
                print(f"âš ï¸ MariaDB ì €ì¥ ì¤‘ ì˜¤ë¥˜: {mariadb_error}")
            else:
                print(f"âš ï¸ MariaDB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ({user_id}/{question_num}): {mariadb_error}")
        
        processing_times["save_results"] = (datetime.now() - stage_start).total_seconds()
        
        # ìµœì¢… ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œë§Œ)
        if not return_result:
            await update_analysis_status(analysis_id, "completed", None, 100.0)
        
        if return_result:
            print(f"ğŸ‰ ë¶„ì„ ì™„ë£Œ: {analysis_id} (ì´ {total_processing_time:.2f}ì´ˆ)")
        else:
            print(f"ë¶„ì„ ì™„ë£Œ: {analysis_id}")
        
        # ê²°ê³¼ ë°˜í™˜ (ë™ê¸° ëª¨ë“œë§Œ)
        if return_result:
            return {
                "status": "completed",
                "results": {
                    "analysis_id": analysis_id,
                    "emotion_analysis": emotion_result,
                    "eye_tracking_analysis": eye_tracking_result,
                    "llm_comment": {
                        "overall_feedback": llm_comment.overall_feedback,
                        "strengths": llm_comment.strengths,
                        "weaknesses": llm_comment.weaknesses,
                        "overall_score": llm_comment.overall_score
                    },
                    "processing_times": processing_times,
                    "total_processing_time": total_processing_time
                }
            }
        else:
            return {
                "status": "completed",
                "results": analysis_data
            }

    except Exception as e:
        if return_result:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({analysis_id}): {str(e)}")
        else:
            print(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({analysis_id}): {str(e)}")
        
        # ì˜¤ë¥˜ ìƒíƒœë¥¼ MongoDBì— ì €ì¥
        error_data = {
            "analysis_id": analysis_id,
            "user_id": user_id,
            "session_id": session_id,
            "s3_bucket": s3_bucket,
            "s3_key": s3_key,
            "error": str(e),
            "created_at": datetime.now().isoformat(),
            "status": "error"
        }
        
        # MongoDBì— ì˜¤ë¥˜ ì •ë³´ ì €ì¥ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ)
        save_success = safe_save_analysis_result(error_data)
        if save_success:
            if return_result:
                print(f"âš ï¸ MongoDBì— ì˜¤ë¥˜ ì •ë³´ ì €ì¥ ì™„ë£Œ")
            else:
                print(f"âš ï¸ MongoDBì— ì˜¤ë¥˜ ì •ë³´ ì €ì¥ ì™„ë£Œ: {analysis_id}")
        else:
            if return_result:
                print(f"âš ï¸ MongoDB ì˜¤ë¥˜ ì •ë³´ ì €ì¥ ì‹¤íŒ¨ - ìŠ¤í‚µë¨")
            else:
                print(f"âš ï¸ MongoDB ì˜¤ë¥˜ ì •ë³´ ì €ì¥ ì‹¤íŒ¨ - ìŠ¤í‚µë¨: {analysis_id}")
        
        return {
            "status": "error",
            "error": str(e)
        }
            
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_dir and os.path.exists(temp_dir):
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)

async def update_analysis_status(analysis_id: str, status: str, stage: Optional[str] = None, progress: float = 0.0):
    """ë¶„ì„ ìƒíƒœë¥¼ DBì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    try:
        update_data = {
            "status": status,
            "progress_percentage": progress,
            "updated_at": datetime.now().isoformat()
        }
        
        if stage:
            update_data["current_stage"] = stage
            
        if status == "processing" and "started_at" not in update_data:
            update_data["started_at"] = datetime.now().isoformat()
        elif status == "completed":
            update_data["completed_at"] = datetime.now().isoformat()
            
        # MongoDB ìƒíƒœ ì—…ë°ì´íŠ¸ (ì—°ê²° ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ)
        from src.db.crud import safe_update_analysis_status
        update_success = safe_update_analysis_status(analysis_id, status)
        if update_success:
            print(f"âœ… ìƒíƒœ ì—…ë°ì´íŠ¸: {analysis_id} -> {status} ({stage}, {progress}%)")
        else:
            print(f"âš ï¸ MongoDB ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ - ìŠ¤í‚µë¨: {analysis_id} -> {status}")
            
    except Exception as e:
        print(f"âš ï¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({analysis_id}): {e}")

async def add_to_gpt_batch_queue(analysis_id: str, user_id: str, question_num: str):
    """GPT ë¶„ì„ ëŒ€ê¸°ì—´ì— ì¶”ê°€í•˜ê³ , ì¡°ê±´ ì¶©ì¡± ì‹œ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    global _pending_gpt_analyses
    _pending_gpt_analyses.append({
        'analysis_id': analysis_id,
        'user_id': user_id,
        'question_num': question_num,
        'added_at': datetime.now()
    })
    print(f"ğŸ“ GPT ë¶„ì„ íì— ì¶”ê°€: {analysis_id} (ëŒ€ê¸° ì¤‘: {len(_pending_gpt_analyses)}ê°œ)")

async def process_gpt_batch():
    """
    ëŒ€ê¸° ì¤‘ì¸ GPT ë¶„ì„ ì‘ì—…ì„ ì¼ê´„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    global _pending_gpt_analyses, _batch_processing_active
    
    if _batch_processing_active or not _pending_gpt_analyses:
        return
    
    _batch_processing_active = True
    batch_to_process = _pending_gpt_analyses.copy()
    _pending_gpt_analyses = []
    
    try:
        print(f"ğŸš€ GPT ë°°ì¹˜ ë¶„ì„ ì‹œì‘: {len(batch_to_process)}ê°œ í•­ëª©")
        
        for i, item in enumerate(batch_to_process, 1):
            try:
                analysis_id = item['analysis_id']
                user_id = item['user_id']
                question_num = item['question_num']
                
                print(f"[{i}/{len(batch_to_process)}] GPT ë¶„ì„ ì‹œì‘: {analysis_id}")
                
                # MongoDBì—ì„œ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                doc = safe_get_analysis_results(analysis_id)
                
                if not doc:
                    print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {analysis_id}")
                    continue
                
                emotion_result = doc.get('emotion_analysis', {})
                eye_tracking_result = doc.get('eye_tracking_analysis', {})
                
                if not emotion_result or not eye_tracking_result:
                    print(f"âš ï¸ ì˜ìƒ ë¶„ì„ ê²°ê³¼ê°€ ë¶ˆì™„ì „í•¨: {analysis_id}")
                    continue
                
                # GPT ë¶„ì„ ìˆ˜í–‰
                llm_comment = await gpt_analyzer.analyze_interview_results(
                    emotion_result, eye_tracking_result, user_id, question_num
                )
                
                # === CLI ì¶œë ¥: ë¶„ì„ ê²°ê³¼ í‘œì‹œ ===
                print(f" ======================================\n")
                print(f"\n ì „ì²´ í”¼ë“œë°±:")
                print(f"   {llm_comment.overall_feedback}") 
                print(f" ======================================\n")
                
                # MariaDB atti_score í…Œì´ë¸”ì— ì¢…í•© ì½”ë©˜íŠ¸ì™€ ì ìˆ˜ ì €ì¥
                try:
                    # MongoDBì—ì„œ ì›ë³¸ ë¶„ì„ ê²°ê³¼ì˜ ì ìˆ˜ë¥¼ ì§ì ‘ ì‚¬ìš© (ì´ë¯¸ 60:40 ë°°ì ìœ¼ë¡œ ì‚°ì¶œë¨)
                    emotion_score_60 = doc.get('emotion_analysis', {}).get('interview_score', 0)  # 60ì  ë§Œì 
                    eye_score_40 = doc.get('eye_tracking_analysis', {}).get('basic_scores', {}).get('total_eye_score', 0)  # 40ì  ë§Œì 
                    
                    # LLM ì „ì²´ í”¼ë“œë°±ì„ ì¢…í•© ì½”ë©˜íŠ¸ë¡œ ì‚¬ìš©
                    total_comment = llm_comment.overall_feedback
                    
                    # audio.answer_score ë° answer_category_result í…Œì´ë¸”ì— ë©´ì ‘íƒœë„ í‰ê°€ ì €ì¥
                    # ë¶€ì •í–‰ìœ„ ê°ì§€ ê²°ê³¼ ì¶”ì¶œ
                    eye_analysis = doc.get('eye_tracking_analysis', {})
                    suspected_copying = eye_analysis.get('analysis_summary', {}).get('total_violations', 0) >= 5
                    suspected_impersonation = eye_analysis.get('analysis_summary', {}).get('face_multiple_detected', False)
                    
                    # GPT ë¶„ì„ ê²°ê³¼ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (LLMCommentì˜ strengths/weaknesses ì‚¬ìš©)
                    strength_keywords = llm_comment.strengths if llm_comment.strengths else ['ì„±ì‹¤í•œ íƒœë„']
                    weakness_keywords = llm_comment.weaknesses if llm_comment.weaknesses else ['ê°œì„  í•„ìš”']
                    
                    gpt_analysis = {
                        'strength_keyword': '\n'.join(strength_keywords),
                        'weakness_keyword': '\n'.join(weakness_keywords)
                    }
                    
                    print(f"ğŸ” GPT í‚¤ì›Œë“œ ì¶”ì¶œ: ê°•ì ={strength_keywords}, ì•½ì ={weakness_keywords}")
                    
                    await mariadb_handler.save_interview_attitude(
                        user_id=user_id,
                        question_num=question_num,
                        emotion_score=emotion_score_60,
                        eye_score=eye_score_40,
                        suspected_copying=suspected_copying,
                        suspected_impersonation=suspected_impersonation,
                        gpt_analysis=gpt_analysis
                    )
                    
                    print(f"ğŸ’¾ MariaDB ë©´ì ‘íƒœë„ í‰ê°€ ì €ì¥ ì™„ë£Œ: {user_id}/{question_num} (ê°ì •:{emotion_score_60:.1f}, ì‹œì„ :{eye_score_40:.1f}, ì»¤ë‹:{suspected_copying}, ëŒ€ë¦¬:{suspected_impersonation})")
                    
                except Exception as mariadb_error:
                    print(f"âš ï¸ MariaDB ì €ì¥ ì‹¤íŒ¨: {mariadb_error}")
                
                # MongoDBì— LLM ê²°ê³¼ ì¶”ê°€ (ì£¼ì„ì²˜ë¦¬)
                # with get_db_session() as db:
                #     collection = db['analysis_results']
                #     collection.update_one(
                #         {'analysis_id': analysis_id},
                #         {
                #             '$set': {
                #                 'llm_comment_id': str(llm_comment.id) if hasattr(llm_comment, 'id') else None,
                #                 'llm_processed_at': datetime.now().isoformat(),
                #                 'overall_score': llm_comment.overall_score
                #             }
                #         }
                #     )
                
                print(f"[{i}/{len(batch_to_process)}] GPT ë¶„ì„ ì™„ë£Œ: {analysis_id} (ì ìˆ˜: {llm_comment.overall_score})")
                
                # ë¶„ì„ ê°„ ëŒ€ê¸° (Rate limiting)
                if i < len(batch_to_process):  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ ëŒ€ê¸°
                    await asyncio.sleep(1)
                    
            except Exception as e:
                print(f"âŒ GPT ë¶„ì„ ì‹¤íŒ¨ ({item['analysis_id']}): {str(e)}")
                continue
        
        print(f"âœ… GPT ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {len(batch_to_process)}ê°œ ì²˜ë¦¬")
        
    except Exception as e:
        print(f"âŒ GPT ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    finally:
        _batch_processing_active = False

async def check_and_trigger_gpt_batch():
    """
    GPT ë¶„ì„ ëŒ€ê¸°ì—´ì„ í™•ì¸í•˜ê³ , ì¡°ê±´(ê°œìˆ˜ ë˜ëŠ” ì‹œê°„)ì— ë”°ë¼ ë°°ì¹˜ë¥¼ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.
    """
    global _pending_gpt_analyses, _batch_processing_active
    
    # ... (í•¨ìˆ˜ ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ ìœ ì§€) ...

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002) 