# ----
# ì‘ì„±ëª©ì  : ì˜ìƒ íŒŒì¼ì—ì„œ ì‹œì„ /ëˆˆê¹œë¹¡ì„ ë¡œê·¸ ìƒì„±
# ì‘ì„±ì¼ : 2025-06-16

# ë³€ê²½ì‚¬í•­ ë‚´ì—­ (ë‚ ì§œ | ë³€ê²½ëª©ì  | ë³€ê²½ë‚´ìš© | ì‘ì„±ì ìˆœìœ¼ë¡œ ê¸°ì…)
# 2025-06-15 | ìµœì´ˆ êµ¬í˜„ | ì›¹ìº  ê¸°ë°˜ ì‹œì„  ì¶”ì  ê¸°ëŠ¥ êµ¬í˜„ | ì´ì¬ì¸
# 2025-06-15 | ê¸°ëŠ¥ ìˆ˜ì • | ì›¹ìº  ëŒ€ì‹  webm ì˜ìƒ ì²˜ë¦¬ ê¸°ëŠ¥ ì¶”ê°€, í”„ë ˆì„ ìŠ¤í‚µ ì˜µì…˜ ì¶”ê°€ | ì´ì¬ì¸
# 2025-06-15 | ê¸°ëŠ¥ ì¶”ê°€ | í‰ê°€ ìë™ ê³„ì‚° ê¸°ëŠ¥ ì¶”ê°€ | ì´ì¬ì¸
# ----------------------------------------------------------------------------------------------------

import cv2
import time
import argparse
import os
import sys
import json
import asyncio
import tempfile
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import numpy as np
from collections import defaultdict

def resize_frame_for_speed(frame, scale=0.7):
    """í”„ë ˆì„ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ì²˜ë¦¬ ì†ë„ í–¥ìƒ"""
    height, width = frame.shape[:2]
    new_width = int(width * scale)
    new_height = int(height * scale)
    return cv2.resize(frame, (new_width, new_height))

def calculate_basic_scores(blink_log_path: Path, gaze_log_path: Path, head_log_path: Path, 
                         anomaly_log_path: Path, total_duration: float) -> Dict[str, Any]:
    """ì²¨ë¶€ëœ main.py ê¸°ë°˜ í‰ê°€ ì‹œìŠ¤í…œ (40ì  ë§Œì )"""
    try:
        # ê¹œë¹¡ì„ ë¡œê·¸ ë¶„ì„ (ì²¨ë¶€ëœ main.pyì™€ ë™ì¼)
        blink_count = 0
        blink_timestamps = []
        if blink_log_path.exists():
            with open(blink_log_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            data = json.loads(line.strip())
                            if 'time' in data:
                                blink_timestamps.append(data['time'])
                                blink_count += 1
                        except:
                            blink_count += 1  # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œì—ë„ ì¹´ìš´íŠ¸
        
        # ì‹œì„  ë¡œê·¸ ë¶„ì„ (ì²¨ë¶€ëœ main.pyì™€ ë™ì¼)
        gaze_data = []
        if gaze_log_path.exists():
            with open(gaze_log_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            data = json.loads(line.strip())
                            gaze_data.append(data)
                        except:
                            continue
        
        # 1. ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (15ì  ë§Œì ) - center ì‹œì„  ë¹„ìœ¨ ê¸°ë°˜
        center_time = 0
        total_gaze_time = 0
        for gaze in gaze_data:
            if 'direction' in gaze and 'start_time' in gaze and 'end_time' in gaze:
                duration = gaze['end_time'] - gaze['start_time']
                total_gaze_time += duration
                if gaze['direction'] == 'center':
                    center_time += duration
        
        concentration_ratio = center_time / total_gaze_time if total_gaze_time > 0 else 0.8
        concentration_score = min(15, concentration_ratio * 15)  # 0~15ì 
        
        # 2. ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚° (15ì  ë§Œì ) - ì‹œì„  ë³€í™” ë¹ˆë„ ê¸°ë°˜
        direction_changes = len(gaze_data)
        stability_ratio = max(0, 1 - (direction_changes / 100))  # 100íšŒ ë³€í™”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        stability_score = min(15, stability_ratio * 15)  # 0~15ì 
        
        # 3. ê¹œë¹¡ì„ ì ìˆ˜ ê³„ì‚° (10ì  ë§Œì ) - ë¶„ë‹¹ 15-20íšŒ ê¸°ì¤€
        blinks_per_minute = (blink_count / (total_duration / 60)) if total_duration > 0 else 0
        if 15 <= blinks_per_minute <= 20:
            blink_score = 10
        elif 10 <= blinks_per_minute <= 25:
            blink_score = 8
        else:
            blink_score = max(0, 10 - abs(blinks_per_minute - 17.5) * 0.5)
        
        # ì´ ì‹œì„  ì ìˆ˜ (40ì  ë§Œì )
        total_eye_score = concentration_score + stability_score + blink_score
        
        return {
            'concentration_score': round(concentration_score, 1),
            'stability_score': round(stability_score, 1),
            'blink_score': round(blink_score, 1),
            'total_eye_score': round(total_eye_score, 1),
            'blink_count': blink_count,
            'blinks_per_minute': round(blinks_per_minute, 1),
            'total_duration': round(total_duration, 1),
            'center_time_ratio': round((center_time / total_gaze_time * 100) if total_gaze_time > 0 else 80, 1),
            'concentration_ratio': round(concentration_ratio, 3),
            'stability_ratio': round(stability_ratio, 3),
            'direction_changes': direction_changes
        }
        
    except Exception as e:
        print(f"âš ï¸ ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ (40ì ì˜ 80%)
        return {
            'concentration_score': 12.0,  # 15ì ì˜ 80%
            'stability_score': 12.0,     # 15ì ì˜ 80%
            'blink_score': 8.0,          # 10ì ì˜ 80%
            'total_eye_score': 32.0,     # 40ì ì˜ 80%
            'blink_count': 0,
            'blinks_per_minute': 0.0,
            'total_duration': total_duration,
            'center_time_ratio': 80.0,
            'concentration_ratio': 0.8,
            'stability_ratio': 0.8,
            'direction_changes': 0
        }

# ìƒëŒ€ importì™€ ì ˆëŒ€ import ëª¨ë‘ ì§€ì› (ì›ë³¸ main.pyì™€ ë™ì¼)
try:
    from .face import FaceMeshDetector
    from .eye import EyeAnalyzer
    from .gaze_analyzer import GazeAnalyzer
    from .yolo_face import YOLOFaceDetector
    from .logger import BlinkLogger, GazeLogger, HeadLogger
    from .anomaly_logger import AnomalyLogger
    from .utils import draw_eye_info, draw_iris_points, draw_head_pose_landmarks, draw_status
except ImportError:
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ì ˆëŒ€ import ì‚¬ìš©
    from face import FaceMeshDetector
    from eye import EyeAnalyzer
    from gaze_analyzer import GazeAnalyzer
    from yolo_face import YOLOFaceDetector
    from logger import BlinkLogger, GazeLogger, HeadLogger
    from anomaly_logger import AnomalyLogger
    from utils import draw_eye_info, draw_iris_points, draw_head_pose_landmarks, draw_status

class EyeTrackingAnalyzer:
    """ì‹œì„  ì¶”ì  ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤ (API í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼)"""
    
    def __init__(self, yolo_model_path: str = None):
        """
        ì‹œì„  ì¶”ì  ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            yolo_model_path: YOLO ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ ê²½ë¡œ
        """
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
        current_dir = os.path.dirname(os.path.abspath(__file__))
        self.yolo_model_path = yolo_model_path or os.path.join(current_dir, 'yolov8n-face-lindevs.pt')
        
    def test_video_basic(self, video_path: str) -> Dict[str, Any]:
        """ë¹„ë””ì˜¤ íŒŒì¼ ê¸°ë³¸ ì •ë³´ í…ŒìŠ¤íŠ¸"""
        try:
            print(f"ğŸ” ë¹„ë””ì˜¤ íŒŒì¼ ê¸°ë³¸ í…ŒìŠ¤íŠ¸: {video_path}")
            
            # ë¹„ë””ì˜¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(video_path):
                print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_path}")
                return {"error": "File not found"}
            
            # OpenCVë¡œ ë¹„ë””ì˜¤ ì—´ê¸° í…ŒìŠ¤íŠ¸
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
                return {"error": "Cannot open video"}
            
            # ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = total_frames / fps if fps > 0 else 0
            
            print(f"âœ… ë¹„ë””ì˜¤ ì •ë³´:")
            print(f"   í•´ìƒë„: {width}x{height}")
            print(f"   FPS: {fps}")
            print(f"   ì´ í”„ë ˆì„: {total_frames}")
            print(f"   ì¬ìƒì‹œê°„: {duration:.2f}ì´ˆ")
            
            # ì²« í”„ë ˆì„ ì½ê¸° í…ŒìŠ¤íŠ¸
            ret, frame = cap.read()
            if not ret:
                print(f"âŒ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                cap.release()
                return {"error": "Cannot read first frame"}
            
            print(f"âœ… ì²« í”„ë ˆì„ ì½ê¸° ì„±ê³µ: {frame.shape}")
            
            # YOLO í…ŒìŠ¤íŠ¸
            try:
                face_detector = YOLOFaceDetector(self.yolo_model_path)
                faces = face_detector.detect_faces(frame)
                print(f"âœ… YOLO ì–¼êµ´ ê°ì§€ í…ŒìŠ¤íŠ¸: {len(faces)}ê°œ ì–¼êµ´ ê°ì§€")
            except Exception as e:
                print(f"âŒ YOLO í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            
            # MediaPipe í…ŒìŠ¤íŠ¸
            try:
                face_analyzer = FaceMeshDetector()
                landmarks = face_analyzer.get_landmarks(frame)
                print(f"âœ… MediaPipe í…ŒìŠ¤íŠ¸: {'ëœë“œë§ˆí¬ ê°ì§€ ì„±ê³µ' if landmarks else 'ëœë“œë§ˆí¬ ê°ì§€ ì‹¤íŒ¨'}")
            except Exception as e:
                print(f"âŒ MediaPipe í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            
            cap.release()
            
            return {
                "video_info": {
                    "width": width,
                    "height": height,
                    "fps": fps,
                    "total_frames": total_frames,
                    "duration": duration
                },
                "face_detection": len(faces) if 'faces' in locals() else 0,
                "landmarks_detected": landmarks is not None if 'landmarks' in locals() else False
            }
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}
        
    async def analyze_video(self, video_path: str, show_window: bool = False, user_id: str = None, question_id: str = None, s3_key: str = None) -> Dict[str, Any]:
        """
        ë¹„ë””ì˜¤ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ì‹œì„  ì¶”ì  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ì›ë³¸ main.pyì™€ ë™ì¼í•œ ë¡œì§)
        
        Args:
            video_path: ë¶„ì„í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            show_window: ì‹œê°í™” ì°½ í‘œì‹œ ì—¬ë¶€ (ë””ë²„ê¹…ìš©)
            user_id: ì‚¬ìš©ì ID (S3 í‚¤ì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ ì§ì ‘ ì „ë‹¬)
            question_id: ì§ˆë¬¸ ID (S3 í‚¤ì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ ì§ì ‘ ì „ë‹¬)  
            s3_key: S3 í‚¤ (user_id, question_id ì¶”ì¶œìš©)
            
        Returns:
            Dict[str, Any]: ì‹œì„  ì¶”ì  ë¶„ì„ ê²°ê³¼
        """
        try:
            # S3 keyì—ì„œ user_idì™€ question_id ì¶”ì¶œ ì‹œë„
            if s3_key:
                print(f"ğŸ” S3 í‚¤ íŒŒì‹± ì‹œë„: {s3_key}")
                # S3 í‚¤ í˜•ì‹: team12/interview_video/{user_id}/{question_id}/filename.mp4
                key_parts = s3_key.split('/')
                print(f"ğŸ” S3 í‚¤ ë¶„í• : {key_parts}")
                
                if len(key_parts) >= 4 and 'interview_video' in key_parts:
                    video_index = key_parts.index('interview_video')
                    if video_index + 2 < len(key_parts):
                        extracted_user_id = key_parts[video_index + 1]
                        extracted_question_id = key_parts[video_index + 2]
                        print(f"ğŸ” S3 keyì—ì„œ ì¶”ì¶œ: user_id={extracted_user_id}, question_id={extracted_question_id}")
                        
                        # ê¸°ì¡´ ê°’ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš©
                        if not user_id:
                            user_id = extracted_user_id
                        if not question_id:
                            question_id = extracted_question_id
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            if not user_id:
                import uuid
                temp_id = str(uuid.uuid4())[:8]
                user_id = f"api_user_{temp_id}"
            if not question_id:
                question_id = "Q1"
                
            print(f"ğŸš€ ì‹œì„  ì¶”ì  ë¶„ì„ ì‹œì‘: {user_id}/{question_id}")
            
            # ë¹„ë™ê¸°ì ìœ¼ë¡œ ë¹„ë””ì˜¤ ì²˜ë¦¬ (user_id, question_id ì „ë‹¬)
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None, self._process_video_sync_with_window, video_path, show_window, user_id, question_id
            )
            return result
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ì‹œì„  ì¶”ì  ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ë¹„ë””ì˜¤ ì‹œì„  ì¶”ì  ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    def _process_video_sync_with_window(self, video_path: str, show_window: bool = False, user_id: str = None, question_id: str = None) -> Dict[str, Any]:
        """ì‹œê°í™” ì˜µì…˜ì„ í¬í•¨í•œ ë™ê¸° ë¹„ë””ì˜¤ ì²˜ë¦¬"""
        try:
            # user_idì™€ question_idê°€ ì—†ìœ¼ë©´ ì„ì‹œ ìƒì„±
            if not user_id or not question_id:
                import uuid
                temp_id = str(uuid.uuid4())[:8]
                if not user_id:
                    user_id = f"api_user_{temp_id}"
                if not question_id:
                    question_id = "Q1"
            
            print(f"ğŸ¯ ì‹œì„  ì¶”ì  ë¶„ì„ ì‹œì‘: {user_id}/{question_id}")
            print(f"ğŸ“¹ ë¹„ë””ì˜¤ íŒŒì¼: {video_path}")
            print(f"ğŸ‘ï¸ ì‹œê°í™” ì°½: {'ON' if show_window else 'OFF'}")
            
            # process_video í•¨ìˆ˜ í˜¸ì¶œ (ì†ë„ ê°œì„ ì„ ìœ„í•´ frame_interval ì¦ê°€)
            result = process_video(video_path, user_id, question_id, frame_interval=6, show_window=show_window)
            
            # ë¡œê·¸ íŒŒì¼ì—ì„œ ê²°ê³¼ ì½ê¸°
            log_dir = Path("logs")
            blink_log = log_dir / f"{user_id}_{question_id}.jsonl"
            gaze_log = log_dir / f"{user_id}_{question_id}_gaze.jsonl"
            head_log = log_dir / f"{user_id}_{question_id}_head.jsonl"
            anomaly_log = log_dir / f"{user_id}_{question_id}_anomalies.jsonl"
            
            print(f"ğŸ“Š ë¡œê·¸ íŒŒì¼ ìƒì„± í™•ì¸:")
            print(f"  - ê¹œë¹¡ì„ ë¡œê·¸: {blink_log.exists()} ({blink_log})")
            print(f"  - ì‹œì„  ë¡œê·¸: {gaze_log.exists()} ({gaze_log})")
            print(f"  - ê³ ê°œ ë¡œê·¸: {head_log.exists()} ({head_log})")
            print(f"  - ì´ìƒ ë¡œê·¸: {anomaly_log.exists()} ({anomaly_log})")
            
            # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
            analysis_result = self._build_analysis_result(
                blink_log, gaze_log, head_log, anomaly_log, video_path, user_id, question_id
            )
            
            print(f"âœ… ì‹œì„  ì¶”ì  ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
            print(f"  - ì´ ë¶„ì„ ì‹œê°„: {analysis_result.get('total_duration', 0):.2f}ì´ˆ")
            print(f"  - ê¹œë¹¡ì„ íšŸìˆ˜: {analysis_result.get('blink_count', 0)}íšŒ")
            print(f"  - ì§‘ì¤‘ë„ ì ìˆ˜: {analysis_result.get('attention_score', 0):.1f}")
            print(f"  - ì‹œì„  ì•ˆì •ì„±: {analysis_result.get('gaze_stability', 0):.1f}")
            
            # ì„ì‹œ ë¡œê·¸ íŒŒì¼ ì •ë¦¬
            for log_file in [blink_log, gaze_log, head_log, anomaly_log]:
                if log_file.exists():
                    log_file.unlink()
            
            return analysis_result
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def _process_video_sync(self, video_path: str) -> Dict[str, Any]:
        """ë™ê¸°ì ìœ¼ë¡œ ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ì›ë³¸ main.py ë¡œì§ ê¸°ë°˜)"""
        try:
            # ì„ì‹œ ì‚¬ìš©ì IDì™€ ì§ˆë¬¸ ID ìƒì„±
            import uuid
            temp_id = str(uuid.uuid4())[:8]
            user_id = f"api_user_{temp_id}"
            question_id = "Q1"
            
            print(f"ğŸ¯ ì‹œì„  ì¶”ì  ë¶„ì„ ì‹œì‘: {user_id}")
            print(f"ğŸ“¹ ë¹„ë””ì˜¤ íŒŒì¼: {video_path}")
            
            # process_video í•¨ìˆ˜ í˜¸ì¶œ (ì›ë³¸ê³¼ ë™ì¼í•œ ì„¤ì •)
            result = process_video(video_path, user_id, question_id, frame_interval=2, show_window=False)
            
            # ë¡œê·¸ íŒŒì¼ì—ì„œ ê²°ê³¼ ì½ê¸°
            log_dir = Path("logs")
            blink_log = log_dir / f"{user_id}_{question_id}.jsonl"
            gaze_log = log_dir / f"{user_id}_{question_id}_gaze.jsonl"
            head_log = log_dir / f"{user_id}_{question_id}_head.jsonl"
            anomaly_log = log_dir / f"{user_id}_{question_id}_anomalies.jsonl"
            
            print(f"ğŸ“Š ë¡œê·¸ íŒŒì¼ ìƒì„± í™•ì¸:")
            print(f"  - ê¹œë¹¡ì„ ë¡œê·¸: {blink_log.exists()} ({blink_log})")
            print(f"  - ì‹œì„  ë¡œê·¸: {gaze_log.exists()} ({gaze_log})")
            print(f"  - ê³ ê°œ ë¡œê·¸: {head_log.exists()} ({head_log})")
            print(f"  - ì´ìƒ ë¡œê·¸: {anomaly_log.exists()} ({anomaly_log})")
            
            # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
            analysis_result = self._build_analysis_result(
                blink_log, gaze_log, head_log, anomaly_log, video_path, user_id, question_id
            )
            
            print(f"âœ… ì‹œì„  ì¶”ì  ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
            print(f"  - ì´ ë¶„ì„ ì‹œê°„: {analysis_result.get('total_duration', 0):.2f}ì´ˆ")
            print(f"  - ê¹œë¹¡ì„ íšŸìˆ˜: {analysis_result.get('blink_count', 0)}íšŒ")
            print(f"  - ì§‘ì¤‘ë„ ì ìˆ˜: {analysis_result.get('attention_score', 0):.1f}")
            print(f"  - ì‹œì„  ì•ˆì •ì„±: {analysis_result.get('gaze_stability', 0):.1f}")
            
            # ì„ì‹œ ë¡œê·¸ íŒŒì¼ ì •ë¦¬
            for log_file in [blink_log, gaze_log, head_log, anomaly_log]:
                if log_file.exists():
                    log_file.unlink()
            
            return analysis_result
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise Exception(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def _build_analysis_result(self, blink_log: Path, gaze_log: Path, 
                              head_log: Path, anomaly_log: Path, video_path: str, user_id: str = None, question_id: str = None) -> Dict[str, Any]:
        """ë¡œê·¸ íŒŒì¼ë“¤ë¡œë¶€í„° ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤."""
        try:
            # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            cap = cv2.VideoCapture(video_path)
            fps = cap.get(cv2.CAP_PROP_FPS) or 30
            
            # ì•ˆì „í•œ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
            raw_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if raw_frame_count <= 0:
                total_frames = int(fps * 60)  # ìµœëŒ€ 60ì´ˆë¡œ ì¶”ì •
            else:
                total_frames = raw_frame_count
                
            duration = total_frames / fps if fps > 0 else 0
            cap.release()
            
            # ë¶€ì •í–‰ìœ„ ê°ì§€ ê²°ê³¼ ìƒì„±
            from .calc.cheat_cal import detect_cheating
            cheating_result = detect_cheating(
                str(head_log), str(anomaly_log), 
                user_id , question_id , video_path
            )
            
            # ë¶€ì •í–‰ìœ„ í†µê³„ ì¶”ì¶œ
            total_violations = 0
            face_multiple_detected = False
            
            print(f"ğŸ” ë¶€ì •í–‰ìœ„ ê°ì§€ ì›ë³¸ ê²°ê³¼: {cheating_result}")
            
            if cheating_result:
                # cheating_resultëŠ” {'user_id': ..., 'question_key': [...]} í˜•íƒœ
                if 'user_id' in cheating_result:
                    actual_user_id = cheating_result['user_id']
                    print(f"ğŸ” ì¶”ì¶œëœ user_id: {actual_user_id}")
                    
                    # question_key ì°¾ê¸° (user_idê°€ ì•„ë‹Œ í‚¤)
                    for key, value in cheating_result.items():
                        if key != 'user_id' and isinstance(value, list):
                            print(f"ğŸ” ê²€ì‚¬ ì¤‘ì¸ í‚¤: {key}, ë°ì´í„°: {value}")
                            cheating_data = value
                            
                            for item in cheating_data:
                                if item.get('category') == 'ë¶€ì •í–‰ìœ„':
                                    total_violations += 1
                                    comment = item.get('comments', '')
                                    if '2ê°œ ê°ì§€ë¨' in comment:
                                        face_multiple_detected = True
                                        print(f"ğŸ” ë‹¤ì¤‘ì–¼êµ´ ê°ì§€ í™•ì¸: {comment}")
                            break
            
            print(f"ğŸ” ë¶€ì •í–‰ìœ„ ê°ì§€ ê²°ê³¼: ì´ {total_violations}íšŒ, ë‹¤ì¤‘ì–¼êµ´: {face_multiple_detected}")
            
            # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° ì‚¬ìš©
            basic_scores = calculate_basic_scores(blink_log, gaze_log, head_log, anomaly_log, duration)
            
            # ë¡œê·¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
            log_files_exist = {
                'blink': blink_log.exists(),
                'gaze': gaze_log.exists(),
                'head': head_log.exists(),
                'anomaly': anomaly_log.exists()
            }
            
            # ê¸°ë³¸ ì ìˆ˜ë¥¼ API í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            return {
                'total_duration': basic_scores['total_duration'],
                'blink_count': basic_scores['blink_count'],
                'blink_rate': basic_scores['blinks_per_minute'],
                'attention_score': basic_scores['concentration_score'],
                'gaze_stability': basic_scores['stability_score'],
                'focus_score': basic_scores['concentration_score'],  # API í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
                'video_info': {
                    'duration': duration,
                    'fps': fps,
                    'total_frames': total_frames
                },
                'basic_scores': basic_scores,  # ê¸°ë³¸ ì ìˆ˜ ì „ì²´ í¬í•¨
                'log_files_status': log_files_exist,
                'analysis_summary': {
                    'total_blinks': basic_scores['blink_count'],
                    'center_time_ratio': basic_scores['center_time_ratio'],
                    'concentration_score': basic_scores['concentration_score'],
                    'stability_score': basic_scores['stability_score'],
                    'blink_score': basic_scores['blink_score'],
                    'total_violations': total_violations,
                    'face_multiple_detected': face_multiple_detected
                }
            }
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ê²°ê³¼ êµ¬ì„± ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                'total_duration': 0,
                'blink_count': 0,
                'blink_rate': 0,
                'attention_score': 0,
                'gaze_stability': 0,
                'focus_score': 0,
                'video_info': {
                    'duration': 0,
                    'fps': 0,
                    'total_frames': 0
                },
                'basic_scores': {
                    'concentration_score': 0,
                    'stability_score': 0,
                    'blink_score': 0,
                    'blink_count': 0,
                    'blinks_per_minute': 0.0,
                    'total_duration': 0,
                    'center_time_ratio': 0
                },
                'error': str(e)
            }



def process_video(video_path, user_id, question_id, frame_interval=3, show_window=False):
    """
    ì˜ìƒ ì²˜ë¦¬ í•¨ìˆ˜ (ì›ë³¸ main.pyì™€ ë™ì¼í•œ ë¡œì§)
    frame_interval: ëª‡ í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬í• ì§€ (ì˜ˆ: 2ë©´ 2í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ ì²˜ë¦¬)
    show_window: ì‹œê°í™” ì°½ í‘œì‹œ ì—¬ë¶€
    """
    # ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬ (ìˆ˜ì •ë¨ - APIìš©)
    if not isinstance(video_path, Path):
        video_path = Path(video_path)
    
    # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if video_path.exists():
        print(f"âœ… ë¹„ë””ì˜¤ íŒŒì¼ í™•ì¸: {video_path}")
    elif not video_path.is_absolute():
        # íŒŒì¼ì´ ì—†ê³  ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš°ì—ë§Œ videos ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬
        video_dir = Path("videos")
        video_dir.mkdir(exist_ok=True)
        alternative_path = video_dir / video_path
        if alternative_path.exists():
            video_path = alternative_path
            print(f"âœ… videos ë””ë ‰í† ë¦¬ì—ì„œ ë°œê²¬: {video_path}")
        else:
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ê²½ë¡œ ì‹œë„: {video_path}")
    
    if not video_path.exists():
        print(f"Error: Video file not found at {video_path}")
        return None
        
    # ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"Error: Could not open video file {video_path}")
        return None
    
    # í”„ë ˆì„ ì •ë³´ (ì•ˆì „í•œ í”„ë ˆì„ ìˆ˜ ê³„ì‚°)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_time = frame_interval/fps if fps > 0 else frame_interval/30
    
    # ì•ˆì „í•œ í”„ë ˆì„ ìˆ˜ ê³„ì‚° - webm íŒŒì¼ì˜ ìŒìˆ˜ ë¬¸ì œ í•´ê²°
    raw_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if raw_frame_count <= 0:
        print("âš ï¸ í”„ë ˆì„ ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¶”ì •ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # FPSì™€ ì˜ˆìƒ ê¸¸ì´ë¡œ ì¶”ì • (ìµœëŒ€ 60ì´ˆ)
        total_frames = int(fps * 60) if fps > 0 else 1800
    else:
        total_frames = raw_frame_count
    
    print(f"ì›ë³¸ FPS: {fps}")
    print(f"ì²˜ë¦¬ FPS: {fps/frame_interval}")
    print(f"ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    print(f"í”„ë ˆì„ ê°„ê²©: {frame_interval}")
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    blink_log = log_dir / f"{user_id}_{question_id}.jsonl"
    gaze_log = log_dir / f"{user_id}_{question_id}_gaze.jsonl"
    head_log = log_dir / f"{user_id}_{question_id}_head.jsonl"
    anomaly_log = log_dir / f"{user_id}_{question_id}_anomalies.jsonl"
    
    # ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ ì‚­ì œ (ìƒˆë¡œ ì‹œì‘) - ì›ë³¸ê³¼ ë™ì¼
    for log_file in [blink_log, gaze_log, head_log, anomaly_log]:
        if log_file.exists():
            log_file.unlink()
    
    # ë¡œê±° ì´ˆê¸°í™” (ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ Path ê°ì²´ ì „ë‹¬)
    blink_logger = BlinkLogger(blink_log)
    gaze_logger = GazeLogger(gaze_log)
    head_logger = HeadLogger(head_log)
    anomaly_logger = AnomalyLogger(anomaly_log)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™” (ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    yolo_model_path = os.path.join(current_dir, 'yolov8n-face-lindevs.pt')
    
    print(f"ğŸ“¦ YOLO ëª¨ë¸ ê²½ë¡œ: {yolo_model_path}")
    print(f"ğŸ“¦ YOLO ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(yolo_model_path)}")
    
    try:
        face_detector = YOLOFaceDetector(yolo_model_path)
        print("âœ… YOLO ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        print(f"âŒ YOLO ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise
    
    try:
        face_analyzer = FaceMeshDetector()
        print("âœ… MediaPipe Face Mesh ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        print(f"âŒ MediaPipe Face Mesh ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise
        
    eye_analyzer = EyeAnalyzer()
    gaze_analyzer = GazeAnalyzer()
    print("âœ… ëª¨ë“  ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ì‹œì‘ ì‹œê°„ ê¸°ë¡
    start_time = time.time()
    frame_count = 0
    processed_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        # í”„ë ˆì„ ìŠ¤í‚µ
        if frame_count % frame_interval != 0:
            frame_count += 1
            continue
            
        # í˜„ì¬ í”„ë ˆì„ ì‹œê°„ ê³„ì‚°
        current_time = processed_count * frame_time
        
        # ì†ë„ ê°œì„ ì„ ìœ„í•œ í”„ë ˆì„ ë¦¬ì‚¬ì´ì§•
        resized_frame = resize_frame_for_speed(frame, scale=0.7)
        
        # YOLOë¡œ ì–¼êµ´ ê°ì§€ (ë¦¬ì‚¬ì´ì§•ëœ í”„ë ˆì„ ì‚¬ìš©)
        faces = face_detector.detect_faces(resized_frame)
        face_count = len(faces)
        
        # ë””ë²„ê¹…: ì²« 100í”„ë ˆì„ì€ ì–¼êµ´ ê°ì§€ ìƒíƒœ ì¶œë ¥
        if processed_count < 100 and processed_count % 10 == 0:
            print(f"[Frame {processed_count}] ê°ì§€ëœ ì–¼êµ´ ìˆ˜: {face_count}")
        
        # ì´ìƒ ìƒí™© ë¡œê¹…
        anomaly_logger.update_state(current_time, face_count)
        
        if face_count != 1:
            frame_count += 1
            processed_count += 1
            continue
            
        # ì–¼êµ´ ëœë“œë§ˆí¬ ë¶„ì„ (ë¦¬ì‚¬ì´ì§•ëœ í”„ë ˆì„ ì‚¬ìš©)
        face_landmarks = face_analyzer.get_landmarks(resized_frame)
        if face_landmarks is None:
            if processed_count < 100 and processed_count % 10 == 0:
                print(f"[Frame {processed_count}] MediaPipe ëœë“œë§ˆí¬ ê°ì§€ ì‹¤íŒ¨")
            frame_count += 1
            processed_count += 1
            continue
        
        # ë””ë²„ê¹…: ëœë“œë§ˆí¬ê°€ ê°ì§€ë˜ë©´ ì¶œë ¥
        if processed_count < 100 and processed_count % 10 == 0:
            print(f"[Frame {processed_count}] ëœë“œë§ˆí¬ ê°ì§€ ì„±ê³µ! ë¶„ì„ ì‹œì‘...")
            
        # ì‹œì„  ë°©í–¥ ë¶„ì„ ë° ê¸°ë¡ (ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€)
        gaze_direction, eye_regions, iris_positions = gaze_analyzer.analyze_gaze(face_landmarks)
        
        # ë””ë²„ê¹…: ì‹œì„  ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        if processed_count < 100 and processed_count % 10 == 0:
            print(f"[Frame {processed_count}] ì‹œì„  ë°©í–¥: {gaze_direction}")
            
        if gaze_direction != "blink":
            gaze_logger.update_gaze(current_time, gaze_direction)
            # ë””ë²„ê¹…: ì‹œì„  ë¡œê¹… í™•ì¸
            if processed_count < 100 and processed_count % 10 == 0:
                print(f"[Frame {processed_count}] ì‹œì„  ë¡œê¹…: {gaze_direction}")
        else:
            blink_logger.log_blink(current_time)
            # ë””ë²„ê¹…: ê¹œë¹¡ì„ ë¡œê¹… í™•ì¸
            if processed_count < 100 and processed_count % 10 == 0:
                print(f"[Frame {processed_count}] ê¹œë¹¡ì„ ê°ì§€!")
            
        # ê³ ê°œ ë°©í–¥ ë¶„ì„ ë° ê¸°ë¡ (ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€)
        head_direction, is_calibrated = gaze_analyzer.analyze_head_pose(face_landmarks, current_time)
        
        # ë””ë²„ê¹…: ê³ ê°œ ë°©í–¥ ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        if processed_count < 100 and processed_count % 10 == 0:
            print(f"[Frame {processed_count}] ê³ ê°œ ë°©í–¥: {head_direction}, ë³´ì •ìƒíƒœ: {is_calibrated}")
            
        if is_calibrated and head_direction != "calibrating":
            head_logger.update_head(current_time, head_direction)
            # ë””ë²„ê¹…: ê³ ê°œ ë¡œê¹… í™•ì¸
            if processed_count < 100 and processed_count % 10 == 0:
                print(f"[Frame {processed_count}] ê³ ê°œ ë¡œê¹…: {head_direction}")
        
        # ì‹œê°í™” (ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬)
        if show_window:
            if eye_regions and iris_positions:
                draw_status(frame, gaze_direction, head_direction, not is_calibrated)
            cv2.imshow('Frame', frame)
            
            # 'q' í‚¤ë¡œ ì¢…ë£Œ
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        # ì§„í–‰ë¥  í‘œì‹œ (ì•ˆì „í•œ í”„ë ˆì„ ìˆ˜ ì‚¬ìš©)
        if frame_count % (frame_interval * 10) == 0 and total_frames > 0:
            progress = (frame_count / total_frames) * 100
            elapsed_time = time.time() - start_time
            processing_fps = processed_count / elapsed_time if elapsed_time > 0 else 0
            print(f"\rì§„í–‰ë¥ : {progress:.1f}% ({frame_count}/{total_frames}) - ì²˜ë¦¬ ì†ë„: {processing_fps:.1f} FPS", end="")
            
        frame_count += 1
        processed_count += 1
    
    print("\nì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ì´ ì²˜ë¦¬ ì‹œê°„: {time.time() - start_time:.1f}ì´ˆ")
    print(f"í‰ê·  ì²˜ë¦¬ ì†ë„: {processed_count / (time.time() - start_time):.1f} FPS")
    
    # ì •ë¦¬
    cap.release()
    if show_window:
        cv2.destroyAllWindows()
    
    # ë¡œê±° ì¢…ë£Œ (ì›ë³¸ê³¼ ë™ì¼)
    current_time = processed_count * frame_time
    blink_logger.force_resolve(current_time)
    gaze_logger.force_resolve(current_time)
    head_logger.force_resolve(current_time)
    anomaly_logger.force_resolve(current_time)
    
    # í‰ê°€ ê³„ì‚° ì‹¤í–‰ (ì›ë³¸ê³¼ ë™ì¼)
    try:
        print("\ní‰ê°€ ê³„ì‚°ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # í‰ê°€ ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œë„ (ì›ë³¸ê³¼ ë™ì¼)
        sys.path.append(os.path.join(os.path.dirname(__file__), "calc"))
        from total_eval_calc import calc_blink_score, calc_eye_contact_score, save_total_eval
        from cheat_cal import detect_cheating
        
        # 1. ê¹œë¹¡ì„ê³¼ ì•„ì´ì»¨íƒ í‰ê°€ (ì›ë³¸ê³¼ ë™ì¼)
        blink_result = calc_blink_score(str(blink_log), user_id)
        eye_contact_result = calc_eye_contact_score(str(gaze_log), user_id)
        
        # í†µí•© ê²°ê³¼ ì €ì¥ (S3 ê²½ë¡œ ê¸°ë°˜ ë™ì  ì„¤ì •)
        eval_result = save_total_eval(user_id, blink_result, eye_contact_result, question_id, str(video_path))
        print("\n[ì˜ì‚¬ì†Œí†µëŠ¥ë ¥ ë° ë©´ì ‘íƒœë„ í‰ê°€ ê²°ê³¼]")
        print(json.dumps(eval_result, ensure_ascii=False, indent=2))
        
        # 2. ë¶€ì •í–‰ìœ„ ê°ì§€ (S3 ê²½ë¡œ ê¸°ë°˜ ë™ì  ì„¤ì •)
        cheat_result = detect_cheating(str(head_log), str(anomaly_log), user_id, question_id, str(video_path))
        print("\n[ë¶€ì •í–‰ìœ„ ê°ì§€ ê²°ê³¼]")
        print(json.dumps(cheat_result, ensure_ascii=False, indent=2))
        
        # ë¶€ì •í–‰ìœ„ ê²°ê³¼ ì €ì¥ (ì›ë³¸ê³¼ ë™ì¼)
        cheat_log = Path("src/eye_tracking/calc") / "cheating_detected.jsonl"
        cheat_log.parent.mkdir(exist_ok=True)
        with open(cheat_log, "a", encoding="utf-8") as f:
            f.write(json.dumps(cheat_result, ensure_ascii=False, indent=2) + "\n\n")
            
        return {
            'blink_result': blink_result,
            'eye_contact_result': eye_contact_result,
            'eval_result': eval_result,
            'cheat_result': cheat_result
        }
        
    except ImportError as e:
        print(f"\ní‰ê°€ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("ë¡œê·¸ íŒŒì¼ë§Œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°ìœ¼ë¡œ ëŒ€ì²´
        duration = processed_count * frame_time
        basic_scores = calculate_basic_scores(blink_log, gaze_log, head_log, anomaly_log, duration)
        
        print(f"\nğŸ“Š ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° ê²°ê³¼:")
        print(f"  - ì§‘ì¤‘ë„: {basic_scores['concentration_score']}")
        print(f"  - ì•ˆì •ì„±: {basic_scores['stability_score']}")
        print(f"  - ê¹œë¹¡ì„: {basic_scores['blink_score']}")
        
        return {
            'basic_scores': basic_scores,
            'duration': duration,
            'log_files_created': True
        }
    except Exception as e:
        print(f"\ní‰ê°€ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì»¤ë§¨ë“œë¼ì¸ ì¸í„°í˜ì´ìŠ¤"""
    parser = argparse.ArgumentParser(description='Process video file for eye tracking analysis')
    parser.add_argument('video_path', type=str, help='Path to the webm video file (relative to videos/ directory or absolute path)')
    parser.add_argument('user_id', type=str, help='User ID (e.g., iv001)')
    parser.add_argument('question_id', type=str, help='Question ID (e.g., Q1)')
    parser.add_argument('--frame-interval', type=int, default=2, help='Process every N-th frame (default: 2)')
    parser.add_argument('--show-window', action='store_true', help='Show visualization window')
    
    args = parser.parse_args()
    
    # ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
    result = process_video(args.video_path, args.user_id, args.question_id, 
                          args.frame_interval, args.show_window)
    
    if result:
        print("\nëª¨ë“  ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 