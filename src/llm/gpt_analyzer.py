# ----
# ì‘ì„±ëª©ì  : GPTë¥¼ í™œìš©í•œ ë©´ì ‘ ë¶„ì„ ë° í‰ê°€ ìƒì„± ëª¨ë“ˆ
# ì‘ì„±ì¼ : 2025-06-17

# ë³€ê²½ì‚¬í•­ ë‚´ì—­ (ë‚ ì§œ | ë³€ê²½ëª©ì  | ë³€ê²½ë‚´ìš© | ì‘ì„±ì ìˆœìœ¼ë¡œ ê¸°ì…)
# 2025-06-15 | ìµœì´ˆ êµ¬í˜„ | FastAPI ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ì— ë”°ë¥¸ êµ¬ì¡°ë¡œ ì¬êµ¬ì„± | ì´ì¬ì¸
# 2025-06-17 | í”„ë¡¬í”„íŠ¸ ê°œì„  | ë©´ì ‘ íƒœë„ í‰ê°€ í”„ë¡¬í”„íŠ¸ êµ¬ì²´í™” ë° ì„¸ë¶„í™” | ì´ì¬ì¸
# 2025-06-24 | YAML ê¸°ë°˜ ì „í™˜ | ëª¨ë“  í•˜ë“œì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ë¥¼ YAML íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ì „í™˜ | ì´ì¬ì¸
# ----

from openai import AsyncOpenAI
import os
import json
import asyncio
import time
import random
from typing import Dict, Any, Optional
from datetime import datetime
from src.db.models import LLMComment
from dotenv import load_dotenv

# .env íŒŒì¼ì„ ëª…ì‹œì  ê²½ë¡œë¡œ ë¡œë“œ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ)
import pathlib
project_root = pathlib.Path(__file__).parent.parent.parent
load_dotenv(project_root / '.env', override=True)

class GPTAnalyzer:
    """GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë©´ì ‘ ë¶„ì„ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³  í”¼ë“œë°±ì„ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str = None, model: str = "gpt-4"):
        """GPT ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        # GPT ë¶„ì„ í™œì„±í™” ì—¬ë¶€ í™•ì¸
        self.enabled = os.getenv('OPENAI_ENABLED', 'true').lower() == 'true'
        
        if not self.enabled:
            print("âš ï¸ OpenAI GPT ë¶„ì„ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            self.api_key = None
            self.client = None
            return
        
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.model = model
        
        if not self.api_key:
            print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.enabled = False
            self.client = None
            return
        
        # API í‚¤ ìœ íš¨ì„± ê²€ì¦
        print("ğŸ” OpenAI API í‚¤ ìœ íš¨ì„± ê²€ì¦ ì¤‘...")
        if not self._validate_api_key():
            print("âŒ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Fallback ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            self.enabled = False
            self.client = None
            return
        
        # AsyncOpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ìë™ ì¬ì‹œë„ ë¹„í™œì„±í™”)
        self.client = AsyncOpenAI(api_key=self.api_key, max_retries=0)
        
        # ëª¨ë¸ë³„ ì„¤ì •
        self._configure_model_settings()
        
        print(f"ğŸ¤– GPT ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“‹ ëª¨ë¸: {self.model}")
        print(f"â±ï¸ ìš”ì²­ ê°„ê²©: {self.request_interval}ì´ˆ")
        print(f"ğŸ”„ ìµœëŒ€ ì¬ì‹œë„: {self.max_retries}íšŒ")
        print(f"â³ íƒ€ì„ì•„ì›ƒ: {self.timeout}ì´ˆ")
        print(f"ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™” (ì„¸ë§ˆí¬ì–´ ì œê±°)")
    
    def _configure_model_settings(self):
        """ëª¨ë¸ë³„ ì„¤ì • ê°’ êµ¬ì„±"""
        if "gpt-4" in self.model.lower():
            self.request_interval = float(os.getenv('OPENAI_GPT4_INTERVAL', '2.0'))  # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê°„ê²© ë‹¨ì¶•
            self.max_retries = int(os.getenv('OPENAI_GPT4_RETRIES', '6'))
            self.base_delay = float(os.getenv('OPENAI_GPT4_DELAY', '3.0'))  # ì¬ì‹œë„ ê°„ê²© ë‹¨ì¶•
            self.timeout = 90
            self.max_tokens = 1500
        else:
            self.request_interval = float(os.getenv('OPENAI_GPT35_INTERVAL', '1.0'))  # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ê°„ê²© ë‹¨ì¶•
            self.max_retries = int(os.getenv('OPENAI_GPT35_RETRIES', '4'))
            self.base_delay = float(os.getenv('OPENAI_GPT35_DELAY', '2.0'))  # ì¬ì‹œë„ ê°„ê²© ë‹¨ì¶•
            self.timeout = 60
            self.max_tokens = 1200
        
        self.last_request_time = 0
    
    def _validate_api_key(self) -> bool:
        """OpenAI API í‚¤ ìœ íš¨ì„±ì„ ë™ê¸°ì ìœ¼ë¡œ ê²€ì¦"""
        try:
            import openai
            from openai import OpenAI
            
            # ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¡œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
            test_client = OpenAI(api_key=self.api_key, max_retries=0)
            
            # 1ë‹¨ê³„: ëª¨ë¸ ëª©ë¡ ìš”ì²­ìœ¼ë¡œ API í‚¤ ê¸°ë³¸ ìœ íš¨ì„± í™•ì¸
            test_client.models.list()
            print("âœ… API í‚¤ ê¸°ë³¸ ì¸ì¦ ì„±ê³µ")
            
            # 2ë‹¨ê³„: ì‚¬ìš©ëŸ‰ ì •ë³´ í™•ì¸ (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                print("ğŸ” ì‚¬ìš©ëŸ‰ ì •ë³´ í™•ì¸ ì¤‘...")
                # OpenAIì˜ usage APIëŠ” íŠ¹ì • ì¡°ê±´ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥
                # ì¡°ì§ ê³„ì •ì´ë‚˜ íŠ¹ì • í”Œëœì—ì„œë§Œ ì§€ì›ë¨
                usage = test_client.usage.retrieve()
                print("ğŸ” ì‚¬ìš©ëŸ‰ ì •ë³´:", usage)
            except Exception as usage_e:
                print("â„¹ï¸ ì‚¬ìš©ëŸ‰ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ê°œì¸ ê³„ì • ë˜ëŠ” ê¶Œí•œ ì œí•œ)")
            
            # 3ë‹¨ê³„: ì‹¤ì œ GPT ìš”ì²­ìœ¼ë¡œ ì‚¬ìš©ëŸ‰ í•œë„ í™•ì¸
            print("ğŸ” GPT ì‚¬ìš©ëŸ‰ í•œë„ í™•ì¸ ì¤‘...")
            response = test_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5
            )
            
            print("âœ… OpenAI API í‚¤ê°€ ìœ íš¨í•˜ê³  ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
            return True
            
        except openai.AuthenticationError:
            print("âŒ API í‚¤ ì¸ì¦ ì˜¤ë¥˜: ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ì…ë‹ˆë‹¤.")
            return False
        except openai.RateLimitError:
            print("âš ï¸ ìœ íš¨í•œ í‚¤ì§€ë§Œ Rate Limitì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
            print("   - ë¶„ë‹¹/ì‹œê°„ë‹¹ ìš”ì²­ í•œë„ ì´ˆê³¼")
            print("   - Fallback ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            return False
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg:
                print(f"âš ï¸ API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼ (429 ì—ëŸ¬)")
                print(f"   - ë¶„ë‹¹/ì‹œê°„ë‹¹ ìš”ì²­ í•œë„ ì´ˆê³¼ ë˜ëŠ” í¬ë ˆë”§ ì†Œì§„")
                print(f"   - Fallback ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            elif "quota" in error_msg.lower() or "insufficient" in error_msg.lower():
                print(f"âš ï¸ API í¬ë ˆë”§ ì™„ì „ ì†Œì§„")
                print(f"   - OpenAI ëŒ€ì‹œë³´ë“œì—ì„œ í¬ë ˆë”§ ì¶©ì „ í•„ìš”")
                print(f"   - Fallback ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            else:
                print(f"â“ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
            return False

    async def analyze_interview_results(self, 
                                      emotion_result: Dict[str, Any], 
                                      eye_tracking_result: Dict[str, Any],
                                      user_id: str, 
                                      question_num: str) -> LLMComment:
        """ì‚¬ìš©ìë³„ ì§ˆë¬¸ë³„ ë©´ì ‘ ê²°ê³¼ ì¢…í•© ë¶„ì„"""
        analysis_id = f"{user_id}_{question_num}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # GPT ë¶„ì„ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ì¦‰ì‹œ fallback ì‚¬ìš©
        if not self.enabled or not self.client:
            print(f"ğŸ“ GPT ë¶„ì„ ë¹„í™œì„±í™”ë¨, fallback ì‚¬ìš©: {analysis_id}")
            return await self._create_fallback_comment(emotion_result, eye_tracking_result, user_id, question_num, analysis_id)
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_prompt(emotion_result, eye_tracking_result, user_id, question_num)
            
            # GPT í˜¸ì¶œ (ë³‘ë ¬ ì²˜ë¦¬)
            response = await self._call_gpt_with_retry(prompt)
            
            # ì‘ë‹µ íŒŒì‹±
            comment = await self._parse_response(response, emotion_result, eye_tracking_result, analysis_id)
            comment.user_id = user_id
            # question_numì€ analysis_idì— í¬í•¨ë˜ì–´ ìˆìŒ
            
            return comment
            
        except Exception as e:
            print(f"âš ï¸ GPT ë¶„ì„ ì‹¤íŒ¨, fallback ì‚¬ìš©: {str(e)}")
            return await self._create_fallback_comment(emotion_result, eye_tracking_result, user_id, question_num, analysis_id)
    
    async def generate_comment(self, 
                             emotion_result: Dict[str, Any], 
                             eye_tracking_result: Dict[str, Any],
                             analysis_id: str) -> LLMComment:
        """ì¼ë°˜ ë¶„ì„ ê²°ê³¼ GPT ì½”ë©˜íŠ¸ ìƒì„±"""
        # GPT ë¶„ì„ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° ì¦‰ì‹œ fallback ì‚¬ìš©
        if not self.enabled or not self.client:
            print(f"ğŸ“ GPT ë¶„ì„ ë¹„í™œì„±í™”ë¨, fallback ì‚¬ìš©: {analysis_id}")
            return await self._create_fallback_comment(emotion_result, eye_tracking_result, analysis_id=analysis_id)
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_prompt(emotion_result, eye_tracking_result)
            
            # GPT í˜¸ì¶œ (ë³‘ë ¬ ì²˜ë¦¬)
            response = await self._call_gpt_with_retry(prompt)
            
            # ì‘ë‹µ íŒŒì‹±
            return await self._parse_response(response, emotion_result, eye_tracking_result, analysis_id)
            
        except Exception as e:
            print(f"âš ï¸ GPT ë¶„ì„ ì‹¤íŒ¨, fallback ì‚¬ìš©: {str(e)}")
            return await self._create_fallback_comment(emotion_result, eye_tracking_result, analysis_id=analysis_id)
    
    async def _call_gpt_with_retry(self, prompt: str) -> str:
        """GPT API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        print(f"ğŸš€ GPT API í˜¸ì¶œ ì‹œì‘ - ëª¨ë¸: {self.model}")
        print(f"ğŸ“¤ ì „ì†¡í•  í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        for attempt in range(self.max_retries):
            try:
                await self._apply_rate_limiting()
                
                print(f"ğŸ”„ ì‹œë„ {attempt + 1}/{self.max_retries}")
                response = await self._make_api_call(prompt, self.model)
                
                if response:
                    print(f"âœ… GPT API ì‘ë‹µ ì„±ê³µ - ì‘ë‹µ ê¸¸ì´: {len(response)} ë¬¸ì")
                    return response
                else:
                    print(f"âš ï¸ ë¹ˆ ì‘ë‹µ ë°›ìŒ (ì‹œë„ {attempt + 1})")
                    
            except Exception as e:
                print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {str(e)}")
                if attempt < self.max_retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´
                    wait_time = (2 ** attempt) * self.base_delay
                    print(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                else:
                    print(f"ğŸ’¥ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨, ìµœì¢… ì˜¤ë¥˜: {str(e)}")
                    
        print("âŒ GPT API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨")
        return ""
    
    async def _apply_rate_limiting(self):
        """ìš”ì²­ ê°„ê²© ì œí•œ ì ìš© (ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ìµœì†Œí•œìœ¼ë¡œ)"""
        current_time = time.time()
        elapsed = current_time - self.last_request_time
        
        if elapsed < self.request_interval:
            wait_time = self.request_interval - elapsed
            print(f"â±ï¸ Rate limiting: {wait_time:.1f}ì´ˆ ëŒ€ê¸°")
            await asyncio.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    async def _make_api_call(self, prompt: str, model: str) -> str:
        """ì‹¤ì œ OpenAI API í˜¸ì¶œ"""
        print(f"ğŸ¤– API í˜¸ì¶œ ì¤‘... (ëª¨ë¸: {model})")
        
        # promptê°€ ì´ë¯¸ ì‹œìŠ¤í…œê³¼ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ê°€ ê²°í•©ëœ í˜•íƒœë¼ê³  ê°€ì •
        # YAMLì—ì„œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ì „ë‹¬
        response = await self.client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=self.max_tokens,
            timeout=self.timeout
        )
        
        return response.choices[0].message.content
    
    def _create_prompt(self, emotion_result: Dict[str, Any], eye_tracking_result: Dict[str, Any], 
                      user_id: str = None, question_num: str = None) -> str:
        """YAML ì„¤ì • ê¸°ë°˜ GPT í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # YAML ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ì„ê¸° import
        try:
            from .keyword_analyzer import keyword_analyzer
            
            # ë¶„ì„ ë°ì´í„° ì¤€ë¹„
            analysis_data = {
                'emotion_score': emotion_result.get('interview_score', 0),
                'eye_score': eye_tracking_result.get('basic_scores', {}).get('total_eye_score', 0),
                'concentration_score': eye_tracking_result.get('basic_scores', {}).get('concentration_score', 0),
                'stability_score': eye_tracking_result.get('basic_scores', {}).get('stability_score', 0),
                'blink_score': eye_tracking_result.get('basic_scores', {}).get('blink_score', 0),
                'total_violations': eye_tracking_result.get('analysis_summary', {}).get('total_violations', 0),
                'face_multiple_detected': eye_tracking_result.get('analysis_summary', {}).get('face_multiple_detected', False),
                'suspected_copying': eye_tracking_result.get('analysis_summary', {}).get('total_violations', 0) >= 5,
                'suspected_impersonation': eye_tracking_result.get('analysis_summary', {}).get('face_multiple_detected', False),
                'dominant_emotions': emotion_result.get('dominant_emotion', 'ì¤‘ë¦½'),
                'emotion_stability': 'ë†’ìŒ' if emotion_result.get('interview_score', 0) >= 50 else 'ë³´í†µ'
            }
            
            # YAML ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt, user_prompt = keyword_analyzer.get_gpt_prompt(analysis_data)
            
            # system_promptì™€ user_promptë¥¼ ê²°í•©
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            print(f"ğŸ” YAML ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
            return full_prompt
            
        except Exception as e:
            print(f"âš ï¸ YAML ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©: {e}")
            return self._create_legacy_prompt(emotion_result, eye_tracking_result, user_id, question_num)
    
    def _create_legacy_prompt(self, emotion_result: Dict[str, Any], eye_tracking_result: Dict[str, Any], 
                             user_id: str = None, question_num: str = None) -> str:
        """YAML ê¸°ë°˜ ìƒì„¸ í”„ë¡¬í”„íŠ¸ ìƒì„± (fallback)"""
        
        # YAML ê¸°ë°˜ í‚¤ì›Œë“œ ë¶„ì„ê¸° ì‚¬ìš©
        try:
            from .keyword_analyzer import keyword_analyzer
            
            # YAML ê¸°ë°˜ ìƒì„¸ GPT í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt, user_prompt = keyword_analyzer.get_detailed_gpt_prompt(
                emotion_result, eye_tracking_result
            )
            
            # system_promptì™€ user_promptë¥¼ ê²°í•©
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            print(f"ğŸ” YAML ê¸°ë°˜ ë ˆê±°ì‹œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
            return full_prompt
            
        except Exception as e:
            print(f"âš ï¸ YAML ê¸°ë°˜ ë ˆê±°ì‹œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ fallback
            return "ë©´ì ‘ ì˜ìƒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì˜ ë©´ì ‘ íƒœë„ë¥¼ 4ì¤„(300ì ì´ë‚´)ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”."
    
    async def _parse_response(self, response: str, emotion_result: Dict[str, Any], 
                             eye_tracking_result: Dict[str, Any], analysis_id: str) -> LLMComment:
        """GPT ì‘ë‹µì„ LLMComment ê°ì²´ë¡œ íŒŒì‹±"""
        try:
            print(f"ğŸ” GPT ì›ë³¸ ì‘ë‹µ: {response[:500]}...")  # ì‘ë‹µ ë‚´ìš© í™•ì¸
            
            overall_feedback = response.strip()
            
            # JSON í˜•íƒœë¡œ ì‘ë‹µí•œ ê²½ìš° í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            if overall_feedback.startswith('{') and overall_feedback.endswith('}'):
                try:
                    import json
                    data = json.loads(overall_feedback)
                    # evaluation í‚¤ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    if 'evaluation' in data:
                        overall_feedback = data['evaluation'].strip()
                        print("âœ… JSONì—ì„œ evaluation í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                    elif 'overall_feedback' in data:
                        overall_feedback = data['overall_feedback'].strip()
                        print("âœ… JSONì—ì„œ overall_feedback í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                    else:
                        # JSONì˜ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                        overall_feedback = list(data.values())[0].strip()
                        print("âœ… JSONì—ì„œ ì²« ë²ˆì§¸ ê°’ ì¶”ì¶œ ì„±ê³µ")
                except json.JSONDecodeError:
                    print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                    pass
            
            # ì‘ë‹µì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if not overall_feedback or len(overall_feedback) < 20:
                print("âš ï¸ GPT ì‘ë‹µì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìŒ, fallback ì‚¬ìš©")
                return await self._create_fallback_comment(emotion_result, eye_tracking_result, analysis_id=analysis_id)
            
            print(f"ğŸ“ ìµœì¢… overall_feedback: {overall_feedback}")
            
            return LLMComment(
                analysis_id=analysis_id,
                overall_score=0.0,
                emotion_feedback="",
                attention_feedback="",
                overall_feedback=overall_feedback,
                improvement_suggestions=[],
                strengths=[],
                weaknesses=[],
                emotion_score=0.0,
                attention_score=0.0,
                stability_score=0.0
            )
            
        except Exception as e:
            print(f"âŒ _parse_response ì˜¤ë¥˜: {str(e)}")
            print(f"âŒ ì‘ë‹µ ë‚´ìš©: {response}")
            return await self._create_fallback_comment(emotion_result, eye_tracking_result, analysis_id=analysis_id)
    
    async def _create_fallback_comment(self, emotion_result: Dict[str, Any], 
                                     eye_tracking_result: Dict[str, Any],
                                     user_id: str = None, question_num: str = None,
                                     analysis_id: str = None) -> LLMComment:
        """Fallback LLMComment ìƒì„±"""
        if not analysis_id:
            analysis_id = f"fallback_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # LLM ê¸°ë°˜ ë™ì  í‰ê°€ ìƒì„± ì‹œë„
        try:
            fallback_comment = await self._generate_fallback_with_llm(emotion_result, eye_tracking_result, user_id, question_num)
            if fallback_comment:
                return fallback_comment
        except Exception as e:
            print(f"âš ï¸ LLM ê¸°ë°˜ fallback ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        # ìµœì¢… fallback: YAML ê¸°ë°˜ ë™ì  í”¼ë“œë°± ìƒì„±
        overall_feedback = self._generate_dynamic_feedback(emotion_result, eye_tracking_result)
        
        comment = LLMComment(
            analysis_id=analysis_id,
            overall_score=0.0,
            emotion_feedback="",
            attention_feedback="",
            overall_feedback=overall_feedback,
            improvement_suggestions=[],
            strengths=[],
            weaknesses=[],
            emotion_score=0.0,
            attention_score=0.0,
            stability_score=0.0
        )
        
        if user_id:
            comment.user_id = user_id
            
        return comment

    async def _generate_fallback_with_llm(self, emotion_result: Dict[str, Any], 
                                         eye_tracking_result: Dict[str, Any],
                                         user_id: str = None, question_num: str = None) -> Optional[LLMComment]:
        """LLMì„ ì‚¬ìš©í•œ fallback ì½”ë©˜íŠ¸ ìƒì„±"""
        try:
            # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë°”ë¡œ í…ìŠ¤íŠ¸ í”¼ë“œë°± ìƒì„±
            prompt = f"""ë©´ì ‘ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 4ì¤„ë¡œ êµ¬ì„±ëœ ë©´ì ‘ íƒœë„ í‰ê°€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

1. ì „ë°˜ì ì¸ ë©´ì ‘ íƒœë„ í‰ê°€
2. í‘œì • í‰ê°€
3. ì‹œì„ ì›€ì§ì„ í‰ê°€  
4. ëˆˆê¹œë¹¡ì„ í‰ê°€

ê³¼ê±°í˜•ìœ¼ë¡œ ì„œìˆ í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            response = await self._call_gpt_with_retry(prompt)
            if response and response.strip():
                overall_feedback = response.strip()
                
                return LLMComment(
                    analysis_id=f"fallback_llm_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    overall_score=0.0,
                    emotion_feedback="",
                    attention_feedback="",
                    overall_feedback=overall_feedback,
                    improvement_suggestions=[],
                    strengths=[],
                    weaknesses=[],
                    emotion_score=0.0,
                    attention_score=0.0,
                    stability_score=0.0
                )
                
        except Exception as e:
            print(f"âš ï¸ LLM fallback ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
        return None

    def _generate_dynamic_feedback(self, emotion_result: Dict[str, Any], 
                                  eye_tracking_result: Dict[str, Any]):
        """YAML ê¸°ë°˜ ë™ì  í”¼ë“œë°± ìƒì„± (ìµœì¢… fallback)"""
        try:
            from .keyword_analyzer import keyword_analyzer
            
            # YAML ê¸°ë°˜ ë™ì  í”¼ë“œë°± ìƒì„±
            feedback = keyword_analyzer.generate_dynamic_feedback(emotion_result, eye_tracking_result)
            print(f"ğŸ” YAML ê¸°ë°˜ ë™ì  í”¼ë“œë°± ìƒì„± ì™„ë£Œ")
            return feedback
            
        except Exception as e:
            print(f"âš ï¸ YAML ê¸°ë°˜ ë™ì  í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")
            # ìµœì†Œí•œì˜ í•˜ë“œì½”ë”©ëœ fallback
            return "ë©´ì ‘ íƒœë„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì„±ì‹¤í•œ ìì„¸ë¥¼ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤."

# í—¬í¼ í•¨ìˆ˜
def create_gpt_analyzer_from_env() -> GPTAnalyzer:
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•˜ì—¬ GPTAnalyzer ìƒì„±"""
    api_key = os.getenv('OPENAI_API_KEY')
    model = os.getenv('OPENAI_MODEL', 'gpt-4')
    return GPTAnalyzer(api_key=api_key, model=model) 