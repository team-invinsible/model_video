# ----
# ÏûëÏÑ±Î™©Ï†Å : MariaDB Ïó∞Í≤∞ Î∞è ÌÖåÏù¥Î∏î Í¥ÄÎ¶¨
# ÏûëÏÑ±Ïùº : 2025-06-12

# Î≥ÄÍ≤ΩÏÇ¨Ìï≠ ÎÇ¥Ïó≠ (ÎÇ†Ïßú | Î≥ÄÍ≤ΩÎ™©Ï†Å | Î≥ÄÍ≤ΩÎÇ¥Ïö© | ÏûëÏÑ±Ïûê ÏàúÏúºÎ°ú Í∏∞ÏûÖ)
# 2025-06-14 | ÏµúÏ¥à Íµ¨ÌòÑ | FastAPI Î≤†Ïä§Ìä∏ ÌîÑÎûôÌã∞Ïä§Ïóê Îî∞Î•∏ Íµ¨Ï°∞Î°ú Ïû¨Íµ¨ÏÑ± | Ïù¥Ïû¨Ïù∏
# 2025-06-14 | ÌÖåÏù¥Î∏î Î¶¨Ìå©ÌÑ∞ÎßÅ | audio.answer_score, answer_category_result ÌÖåÏù¥Î∏î Íµ¨Ï°∞Î°ú Î≥ÄÍ≤Ω | Ïù¥Ïû¨Ïù∏
# 2025-06-24 | Î©¥Ï†ëÌÉúÎèÑ Ï†ÑÏö© | INTERVIEW_ATTITUDE Ïπ¥ÌÖåÍ≥†Î¶¨ Ï†ÑÏö© Ï†ÄÏû• ÏãúÏä§ÌÖú Íµ¨ÌòÑ | Ïù¥Ïû¨Ïù∏
# 2025-06-24 | ID ÌòïÏãù Î≥ÄÍ≤Ω | INTV_ANS_IDÎ•º userId0questionNum, ANS_CAT_RESULT_IDÎ•º userId0questionNum0 ÌòïÏãùÏúºÎ°ú Î≥ÄÍ≤Ω | Ïù¥Ïû¨Ïù∏
# ----

import asyncio
import logging
from contextlib import asynccontextmanager
from typing import Optional, Dict, Any, List
import aiomysql
from datetime import datetime
import json
import os
from dotenv import load_dotenv
from .models import LLMComment

# ÌôòÍ≤ΩÎ≥ÄÏàò Î°úÎìú
load_dotenv()

logger = logging.getLogger(__name__)

class MariaDBHandler:
    """MariaDB Ïó∞Í≤∞ Î∞è audio Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ answer_score, answer_category_result ÌÖåÏù¥Î∏î Í¥ÄÎ¶¨"""
    
    def __init__(self):
        self.pool: Optional[aiomysql.Pool] = None
        self.host = os.getenv("MARIADB_HOST", "localhost")
        self.port = int(os.getenv("MARIADB_PORT", "3306"))
        self.user = os.getenv("MARIADB_USER", "root")
        self.password = os.getenv("MARIADB_PASSWORD", "")
        self.database = os.getenv("MARIADB_DATABASE", "audio")
        
    async def create_pool(self):
        """MariaDB Ïó∞Í≤∞ ÌíÄ ÏÉùÏÑ±"""
        try:
            self.pool = await aiomysql.create_pool(
                host=self.host,
                port=self.port,
                user=self.user,
                password=self.password,
                db=self.database,
                charset='utf8mb4',
                autocommit=True,
                minsize=1,
                maxsize=10
            )
            logger.info("MariaDB Ïó∞Í≤∞ ÌíÄÏù¥ ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.")
            
            # ÌÖåÏù¥Î∏î ÏÉùÏÑ±
            await self._create_tables()
            
        except Exception as e:
            logger.error(f"MariaDB Ïó∞Í≤∞ ÌíÄ ÏÉùÏÑ± Ïã§Ìå®: {e}")
            raise
    
    async def close_pool(self):
        """MariaDB Ïó∞Í≤∞ ÌíÄ Ï¢ÖÎ£å"""
        if self.pool:
            self.pool.close()
            await self.pool.wait_closed()
            logger.info("MariaDB Ïó∞Í≤∞ ÌíÄÏù¥ Ï¢ÖÎ£åÎêòÏóàÏäµÎãàÎã§.")
    
    async def _create_tables(self):
        """audio Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê ÌïÑÏöîÌïú ÌÖåÏù¥Î∏îÎì§ÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§."""
        # Í∏∞Ï°¥ Î∂àÌïÑÏöîÌïú ÌÖåÏù¥Î∏îÎì§ ÏÇ≠Ï†ú

        
        # 1. answer_score ÌÖåÏù¥Î∏î ÏÉùÏÑ±
        create_answer_score_table = """
        CREATE TABLE IF NOT EXISTS answer_score (
            ANS_SCORE_ID BIGINT PRIMARY KEY NOT NULL COMMENT 'ÎãµÎ≥Ä ÌèâÍ∞Ä ID (userId0questionNum ÌòïÏãù)',
            INTV_ANS_ID BIGINT NOT NULL COMMENT 'Î©¥Ï†ë ÎãµÎ≥Ä ID (userId)',
            ANS_SUMMARY TEXT NULL COMMENT 'ÎãµÎ≥Ä ÏöîÏïΩ',
            EVAL_SUMMARY TEXT NULL COMMENT 'Ï†ÑÏ≤¥ ÌèâÍ∞Ä ÏöîÏïΩ',
            INCOMPLETE_ANSWER BOOLEAN NULL DEFAULT FALSE COMMENT 'ÎØ∏ÏôÑÎ£å Ïó¨Î∂Ä',
            INSUFFICIENT_CONTENT BOOLEAN NULL DEFAULT FALSE COMMENT 'ÎÇ¥Ïö© Î∂ÄÏ°± Ïó¨Î∂Ä',
            SUSPECTED_COPYING BOOLEAN NULL DEFAULT FALSE COMMENT 'Ïª§Îãù ÏùòÏã¨ Ïó¨Î∂Ä (ÏãúÏÑ† Î∂ÑÏÇ∞)',
            SUSPECTED_IMPERSONATION BOOLEAN NULL DEFAULT FALSE COMMENT 'ÎåÄÎ¶¨ ÏãúÌóò ÏùòÏã¨ Ïó¨Î∂Ä (Îã§Ï§ë ÏñºÍµ¥)',
            RGS_DTM TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'Îì±Î°ù ÏùºÏãú',
            UPD_DTM TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'ÏàòÏ†ï ÏùºÏãú',
            
            INDEX idx_intv_ans_id (INTV_ANS_ID),
            INDEX idx_suspected_copying (SUSPECTED_COPYING),
            INDEX idx_suspected_impersonation (SUSPECTED_IMPERSONATION),
            INDEX idx_rgs_dtm (RGS_DTM)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci 
        COMMENT='ÎãµÎ≥Ä ÌèâÍ∞Ä ÌÖåÏù¥Î∏î (Î©¥Ï†ëÌÉúÎèÑ Î∂ÄÏ†ïÌñâÏúÑ Í∞êÏßÄ)';
        """
        
        # 2. answer_category_result ÌÖåÏù¥Î∏î ÏÉùÏÑ±
        create_answer_category_result_table = """
        CREATE TABLE IF NOT EXISTS answer_category_result (
            ANS_CAT_RESULT_ID BIGINT PRIMARY KEY NOT NULL COMMENT 'ÎãµÎ≥Ä Ìï≠Î™©Î≥Ñ ÌèâÍ∞Ä ID (userId0questionNum0 ÌòïÏãù)',
            EVAL_CAT_CD VARCHAR(20) NOT NULL COMMENT 'ÌèâÍ∞Ä Ìï≠Î™© ÏΩîÎìú (INTERVIEW_ATTITUDE)',
            ANS_SCORE_ID BIGINT NOT NULL COMMENT 'ÎãµÎ≥Ä ÌèâÍ∞Ä ID',
            ANS_CAT_SCORE DOUBLE NULL COMMENT 'Ìï≠Î™©Î≥Ñ Ï†êÏàò (ÌëúÏ†ï+ÏãúÏÑ† Ï¥ùÌï©)',
            STRENGTH_KEYWORD TEXT NULL COMMENT 'Í∞ïÏ†ê ÌÇ§ÏõåÎìú (GPT Î∂ÑÏÑù)',
            WEAKNESS_KEYWORD TEXT NULL COMMENT 'ÏïΩÏ†ê ÌÇ§ÏõåÎìú (GPT Î∂ÑÏÑù)',
            RGS_DTM TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP COMMENT 'Îì±Î°ù ÏùºÏãú',
            
            FOREIGN KEY (ANS_SCORE_ID) REFERENCES answer_score(ANS_SCORE_ID) ON DELETE CASCADE,
            INDEX idx_eval_cat_cd (EVAL_CAT_CD),
            INDEX idx_ans_score_id (ANS_SCORE_ID),
            INDEX idx_ans_cat_score (ANS_CAT_SCORE),
            INDEX idx_rgs_dtm (RGS_DTM),
            UNIQUE KEY unique_score_category (ANS_SCORE_ID, EVAL_CAT_CD)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci 
        COMMENT='ÎãµÎ≥Ä Ìï≠Î™©Î≥Ñ ÌèâÍ∞Ä Í≤∞Í≥º ÌÖåÏù¥Î∏î (Î©¥Ï†ëÌÉúÎèÑ Ï†ÑÏö©)';
        """
        
        async with self.pool.acquire() as conn:
            async with conn.cursor() as cursor:
                await cursor.execute(create_answer_score_table)
                await cursor.execute(create_answer_category_result_table)
                logger.info("audio Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÖåÏù¥Î∏îÏù¥ ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.")
    
    # async def _drop_unnecessary_tables(self):
    #     """Í∏∞Ï°¥ Î∂àÌïÑÏöîÌïú ÌÖåÏù¥Î∏îÎì§ÏùÑ ÏÇ≠Ï†úÌï©ÎãàÎã§."""
    #     tables_to_drop = [
    #         'atti_score',  # Í∏∞Ï°¥ ÌÖåÏù¥Î∏î ÏÇ≠Ï†ú
    #     ]
        
    #     try:
    #         async with self.pool.acquire() as conn:
    #             async with conn.cursor() as cursor:
    #                 for table in tables_to_drop:
    #                     try:
    #                         await cursor.execute(f"DROP TABLE IF EXISTS {table}")
    #                         logger.info(f"Í∏∞Ï°¥ ÌÖåÏù¥Î∏î {table} ÏÇ≠Ï†úÎê®")
    #     except Exception as e:
    #         logger.warning(f"ÌÖåÏù¥Î∏î ÏÇ≠Ï†ú Ï§ë Ïò§Î•ò (Î¨¥Ïãú Í∞ÄÎä•): {e}")
    
    @asynccontextmanager
    async def get_connection(self):
        """MariaDB Ïó∞Í≤∞ÏùÑ Í∞ÄÏ†∏Ïò§Îäî Ïª®ÌÖçÏä§Ìä∏ Îß§ÎãàÏ†Ä"""
        if not self.pool:
            await self.create_pool()
        
        async with self.pool.acquire() as conn:
            try:
                yield conn
            except Exception as e:
                await conn.rollback()
                logger.error(f"MariaDB Ìä∏ÎûúÏû≠ÏÖò Î°§Î∞±: {e}")
                raise
    
    async def get_analysis_summary(self, analysis_id: str) -> Optional[Dict[str, Any]]:
        """Î∂ÑÏÑù ÏöîÏïΩ Ï†ïÎ≥¥ Ï°∞Ìöå"""
        try:
            async with self.get_connection() as conn:
                async with conn.cursor(aiomysql.DictCursor) as cursor:
                    query = """
                    SELECT * FROM analysis_summary 
                    WHERE analysis_id = %s
                    """
                    await cursor.execute(query, (analysis_id,))
                    result = await cursor.fetchone()
                    return dict(result) if result else None
                    
        except Exception as e:
            logger.error(f"Î∂ÑÏÑù ÏöîÏïΩ Ï°∞Ìöå Ïã§Ìå®: {e}")
            return None
    
    async def get_recent_analyses(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ÏµúÍ∑º Î∂ÑÏÑù Í≤∞Í≥º Î™©Î°ù Ï°∞Ìöå"""
        try:
            async with self.get_connection() as conn:
                async with conn.cursor(aiomysql.DictCursor) as cursor:
                    query = """
                    SELECT * FROM analysis_summary 
                    ORDER BY created_at DESC 
                    LIMIT %s
                    """
                    await cursor.execute(query, (limit,))
                    results = await cursor.fetchall()
                    return [dict(result) for result in results]
                    
        except Exception as e:
            logger.error(f"ÏµúÍ∑º Î∂ÑÏÑù Î™©Î°ù Ï°∞Ìöå Ïã§Ìå®: {e}")
            return []
    
    async def update_analysis_status(self, analysis_id: str, status: str, 
                                   current_stage: str = None, progress: float = None) -> bool:
        """Î∂ÑÏÑù ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏"""
        try:
            async with self.get_connection() as conn:
                async with conn.cursor() as cursor:
                    # ÎèôÏ†Å ÏøºÎ¶¨ ÏÉùÏÑ±
                    update_fields = ["analysis_status = %s", "updated_at = CURRENT_TIMESTAMP"]
                    params = [status]
                    
                    if current_stage:
                        update_fields.append("current_stage = %s")
                        params.append(current_stage)
                    
                    if progress is not None:
                        update_fields.append("progress_percentage = %s")
                        params.append(progress)
                    
                    # ÏãúÏûë ÏãúÍ∞Ñ ÏÑ§Ï†ï
                    if status == 'processing' and current_stage == 'download':
                        update_fields.append("started_at = CURRENT_TIMESTAMP")
                    
                    params.append(analysis_id)
                    
                    query = f"""
                    UPDATE analysis_summary 
                    SET {', '.join(update_fields)}
                    WHERE analysis_id = %s
                    """
                    
                    await cursor.execute(query, params)
                    return True
                    
        except Exception as e:
            logger.error(f"Î∂ÑÏÑù ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏ Ïã§Ìå®: {e}")
            return False
    
    async def create_analysis_record(self, analysis_id: str, user_id: str = None, 
                                   session_id: str = None, question_id: str = 'Q1',
                                   video_filename: str = None, video_path: str = None,
                                   file_size: int = None) -> bool:
        """ÏÉàÎ°úÏö¥ Î∂ÑÏÑù Î†àÏΩîÎìú ÏÉùÏÑ±"""
        try:
            async with self.get_connection() as conn:
                async with conn.cursor() as cursor:
                    insert_query = """
                    INSERT INTO analysis_summary (
                        analysis_id, user_id, session_id, question_id,
                        video_filename, video_path, file_size,
                        analysis_status, progress_percentage
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, 'pending', 0)
                    """
                    
                    await cursor.execute(insert_query, (
                        analysis_id, user_id, session_id, question_id,
                        video_filename, video_path, file_size
                    ))
                    
                    logger.info(f"Î∂ÑÏÑù Î†àÏΩîÎìú ÏÉùÏÑ± ÏôÑÎ£å: {analysis_id}")
                    return True
                    
        except Exception as e:
            logger.error(f"Î∂ÑÏÑù Î†àÏΩîÎìú ÏÉùÏÑ± Ïã§Ìå®: {e}")
            return False

    async def save_interview_attitude(self, user_id: str, question_num: str, 
                                     emotion_score: float, eye_score: float,
                                     suspected_copying: bool = False, 
                                     suspected_impersonation: bool = False,
                                     gpt_analysis: Dict[str, str] = None) -> bool:
        """audio.answer_score Î∞è answer_category_result ÌÖåÏù¥Î∏îÏóê Î©¥Ï†ëÌÉúÎèÑ ÌèâÍ∞Ä Ï†ÄÏû•"""
        try:
            # ANS_SCORE_ID ÏÉùÏÑ±: {userId}0{question_num}
            ans_score_id = int(f"{user_id}0{question_num}")
            # INTV_ANS_ID ÏÉùÏÑ±: {userId}0{questionNum} ÌòïÏãù
            intv_ans_id = int(f"{user_id}0{question_num}")
            # ANS_CAT_RESULT_ID ÏÉùÏÑ±: {userId}0{questionNum}0 ÌòïÏãù  
            ans_cat_result_id = int(f"{user_id}0{question_num}0")
            total_score = emotion_score + eye_score
            
            # GPT Î∂ÑÏÑù Í≤∞Í≥ºÏóêÏÑú ÌÇ§ÏõåÎìú Ï∂îÏ∂ú
            strength_keyword = ""
            weakness_keyword = ""
            if gpt_analysis:
                strength_keyword = gpt_analysis.get('strength_keyword', '')
                weakness_keyword = gpt_analysis.get('weakness_keyword', '')
            
            async with self.get_connection() as conn:
                async with conn.cursor() as cursor:
                    # 1. answer_score ÌÖåÏù¥Î∏îÏóê UPSERT
                    answer_score_query = """
                    INSERT INTO answer_score (
                        ANS_SCORE_ID, INTV_ANS_ID, SUSPECTED_COPYING, SUSPECTED_IMPERSONATION
                    ) VALUES (%s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                        SUSPECTED_COPYING = VALUES(SUSPECTED_COPYING),
                        SUSPECTED_IMPERSONATION = VALUES(SUSPECTED_IMPERSONATION),
                        UPD_DTM = CURRENT_TIMESTAMP
                    """
                    
                    await cursor.execute(answer_score_query, (
                        ans_score_id, intv_ans_id, suspected_copying, suspected_impersonation
                    ))
                    
                    # 2. answer_category_result ÌÖåÏù¥Î∏îÏóê UPSERT (Î©¥Ï†ëÌÉúÎèÑÎßå)
                    category_result_query = """
                    INSERT INTO answer_category_result (
                        ANS_CAT_RESULT_ID, EVAL_CAT_CD, ANS_SCORE_ID, ANS_CAT_SCORE, 
                        STRENGTH_KEYWORD, WEAKNESS_KEYWORD
                    ) VALUES (%s, %s, %s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                        ANS_CAT_SCORE = VALUES(ANS_CAT_SCORE),
                        STRENGTH_KEYWORD = VALUES(STRENGTH_KEYWORD),
                        WEAKNESS_KEYWORD = VALUES(WEAKNESS_KEYWORD),
                        RGS_DTM = CURRENT_TIMESTAMP
                    """
                    
                    await cursor.execute(category_result_query, (
                        ans_cat_result_id, 'INTERVIEW_ATTITUDE', ans_score_id, total_score,
                        strength_keyword, weakness_keyword
                    ))
                    
                    logger.info(f"Î©¥Ï†ëÌÉúÎèÑ Ï†ÄÏû• ÏôÑÎ£å: ANS_SCORE_ID={ans_score_id}, ANS_CAT_RESULT_ID={ans_cat_result_id} - ÌëúÏ†ï:{emotion_score}, ÏãúÏÑ†:{eye_score}, Ï¥ùÌï©:{total_score}")
                    logger.info(f"Î∂ÄÏ†ïÌñâÏúÑ Í∞êÏßÄ: Ïª§Îãù={suspected_copying}, ÎåÄÎ¶¨ÏãúÌóò={suspected_impersonation}")
                    print(f"üîç MariaDB Ï†ÄÏû•: user_id={user_id}, question_num={question_num}")
                    print(f"üîç ID ÏÉùÏÑ±: ANS_SCORE_ID={ans_score_id}, INTV_ANS_ID={intv_ans_id}, ANS_CAT_RESULT_ID={ans_cat_result_id}")
                    print(f"üîç Î∂ÄÏ†ïÌñâÏúÑ Í≤∞Í≥º: Ïª§Îãù={suspected_copying}, ÎåÄÎ¶¨ÏãúÌóò={suspected_impersonation}")
                    return True
                    
        except Exception as e:
            logger.error(f"Î©¥Ï†ëÌÉúÎèÑ Ï†ÄÏû• Ïã§Ìå®: {e}")
            return False

    async def get_interview_attitude(self, user_id: str, question_num: str = None) -> Optional[Dict]:
        """Î©¥Ï†ëÌÉúÎèÑ ÌèâÍ∞Ä Í≤∞Í≥º Ï°∞Ìöå"""
        try:
            async with self.get_connection() as conn:
                async with conn.cursor(aiomysql.DictCursor) as cursor:
                    if question_num:
                        ans_score_id = int(f"{user_id}0{question_num}")
                        query = """
                        SELECT 
                            a.ANS_SCORE_ID, a.INTV_ANS_ID, a.SUSPECTED_COPYING, a.SUSPECTED_IMPERSONATION,
                            c.ANS_CAT_RESULT_ID, c.ANS_CAT_SCORE, c.STRENGTH_KEYWORD, c.WEAKNESS_KEYWORD, c.RGS_DTM
                        FROM answer_score a
                        LEFT JOIN answer_category_result c ON a.ANS_SCORE_ID = c.ANS_SCORE_ID 
                        WHERE a.ANS_SCORE_ID = %s AND c.EVAL_CAT_CD = 'INTERVIEW_ATTITUDE'
                        """
                        await cursor.execute(query, (ans_score_id,))
                        return await cursor.fetchone()
                    else:
                        # ÌäπÏ†ï ÏÇ¨Ïö©ÏûêÏùò Î™®Îì† ÏßàÎ¨∏ Ï°∞Ìöå (INTV_ANS_IDÍ∞Ä userId0ÏúºÎ°ú ÏãúÏûëÌïòÎäî Í≤ÉÎì§)
                        user_pattern = f"{user_id}0%"
                        query = """
                        SELECT 
                            a.ANS_SCORE_ID, a.INTV_ANS_ID, a.SUSPECTED_COPYING, a.SUSPECTED_IMPERSONATION,
                            c.ANS_CAT_RESULT_ID, c.ANS_CAT_SCORE, c.STRENGTH_KEYWORD, c.WEAKNESS_KEYWORD, c.RGS_DTM
                        FROM answer_score a
                        LEFT JOIN answer_category_result c ON a.ANS_SCORE_ID = c.ANS_SCORE_ID 
                        WHERE CAST(a.INTV_ANS_ID AS CHAR) LIKE %s AND c.EVAL_CAT_CD = 'INTERVIEW_ATTITUDE'
                        ORDER BY a.ANS_SCORE_ID
                        """
                        await cursor.execute(query, (user_pattern,))
                        return await cursor.fetchall()
                        
        except Exception as e:
            logger.error(f"Î©¥Ï†ëÌÉúÎèÑ Ï°∞Ìöå Ïã§Ìå®: {e}")
            return None

# Ï†ÑÏó≠ MariaDB Ìï∏Îì§Îü¨ Ïù∏Ïä§ÌÑ¥Ïä§
mariadb_handler = MariaDBHandler() 